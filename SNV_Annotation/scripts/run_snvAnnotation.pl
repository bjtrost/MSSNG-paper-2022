#!/tools/perl/5.10.0/bin/perl
use strict;
use POSIX qw(strftime);

our $AUTHOR =   '$Author: Thomas Nalpathamkalam <thomas.nalpathamkalam@sickkids.ca> $';

## Main pipeline script accept
##required perl5.20 and some special perl packages. 
 
=head1 General Information
	TCAG annotation pipeline can be used to annnotate variants in vcf, mssng or custom (ie, annovar 1-based) 
	formats. Custom input file should be a tab-delimited text with at least following columns:
	
	chromosome
	start_coordinate
	end_coordinate
	ref_allele
	alt_allele
	
	Any additional columns are ignored by pipeline but will populate into final output file. IMPORTANT: Make sure to provide an header line starting with #.
	 
=cut

=head1 Requirements
	perl v20.x
	Annovar ( http://annovar.openbioinformatics.org/en/latest/ )
	bedops
	bcftools
	 
=cut

=head1 Overall Annotation Process

The TCAG annotation pipeline uses ANNOVAR to functionally annotate these small variants.
In order to accurately add gene-based, region-based and filter-based annotations,
the original VCF file generated by the variant caller needs to be converted into an ANNOVAR compatible format.
The conversion involves variant decomposition (splitting of variants with two alternate alleles into multiple rows),
left-aligning indels on the forward strand of the reference genome and normalization.
For indels, the normalization sometimes shifts the position of the variants.
The 'GT_PreNorm' captures the genotype before variant decomposition and 'Original_VCFKey'
captures the position of the variant before normalization.

=cut

use 5.020;
use threads;
use Data::Dumper;
use Parallel::ForkManager;
use Time::Piece;
use Pod::Usage;
use Getopt::Long;    # qw(GetOptions);
use File::Basename;
use File::stat;
use FindBin;
use IO::File;
use lib "$FindBin::Bin";
use List::Util qw( min max );
use lib dirname($0);
use Cwd qw();
use Vcfparse;    # edited Feb 28,2020
use AnnotationEngine;
use Carp;
use Carp qw(cluck longmess shortmess);
use Term::ANSIColor;
use Term::ANSIColor qw( colored );
use JSON;
use annovar;
use PipelineExtra;
use MSSNG;
use APPRIS;




my %options = ();

my $keep_temp;
my $log_dir;
my $add_cols;
my $sample2ext;
my (
	$input,    $config,     $in_file_type, $work_dir,
	$is_final, $cores,      $cov_file,     $ex_target_bed,
	$somatic,  $vcf_genome, $d_gear,       $dng_vcf,
	$no_hgmd,  $easy_norm
);

GetOptions(
	\%options,          "i|input=s",
	"f|config=s",       "m|type=s",
	"o|outdir=s",       "l|logdir=s",
	"c|post-type=s",    "r|threads=i",
	"s|somatic",        "g|genome=s",
	"d|dgear",          "v|cov-file=s",
	"b|dng-file=s",     "t|exome-target=s",
	"k|keep_temp",      "x|pgx",
	"a|vcfout",         "T|vcf2tab",
	"ST|sample=s",      "u|out_format",
	"j|add_col=s",      "oc|out_config=s",
	"nh|no_hgmd",       "p|splicing_threshold=i",
	"e|neargene=i",     "q|no_bgzip",
	"cr|check-ref=s",   "pd|ped",
	"hv|hgvs",          "es|exonicsplicing",
	"BL|build=s",       "IM|impact",
	"AP|appris=s",      "PF|appris_flags=s",
	"GF|custom-gene=s", "CG|custom-genome=s",
	"sk|skip_norm",     "h|help"
  )
  or pod2usage(
	-verbose => 1,
	-exitval => 5,
	-output  => \*STDOUT,
	-message => "\n**Invalid argument:**\n"
  );

if ( exists $options{h} ) {
	pod2usage(
		-verbose => 1,
		-exitval => 0,
		-output  => \*STDOUT,
		-message => "\n**Usage:**\n"
	);
}

#my $check_pass = validate_params(\%options);
my $this_time = localtime;
print STDOUT "\[$this_time\] Pipeline started..\n";

my %builds = (
	'hg19' => 1,
	'hg38' => 1,
);

my $g_build = "hg19";
if ( defined $options{BL} ) {
	$g_build = $options{BL};
}

my $calc_impact = 0;
if ( defined $options{IM} ) {
	$calc_impact = 1;
}

if ( not exists $builds{$g_build} ) {
	usage("Build \' $g_build \' is not valid");
}

#hard coded
my $pipeline_rev = "rev27.3" . "_" . $g_build;
my $dp_python =
"/hpf/largeprojects/tcagstor/users/gkaur/more/workspace/python_workspace/gkaur_pythontools/annotation/add_coverage.v0.1.py";
my $dp_python_gagan =
"export PYTHONPATH=/hpf/largeprojects/tcagstor/users/gkaur/more/tools/PyVCF/PyVCF-master.20170913/lib/python3.4/site-packages:/hpf/largeprojects/tcagstor/users/gkaur/more/workspace/python_workspace/gkaur_pythontools:\$PYTHONPATH";

my %process_status_pre = ();
$process_status_pre{'preprocess'}{start} = $this_time;
my @jobnames = ();

$input         = $options{i} if defined $options{i};    ## input file
$config        = $options{f} if defined $options{f};
$in_file_type  = $options{m} if defined $options{m};
$work_dir      = $options{o} if defined $options{o};
$is_final      = $options{c} if defined $options{c};
$cores         = $options{r} if defined $options{r};
$cov_file      = $options{v} if defined $options{v};
$ex_target_bed = $options{t} if defined $options{t};

my $original_input = $input;
my $out_format     = "tsv";
if ( defined $options{a} ) {
	$out_format = $options{a};
}

$add_cols = $options{j};
warn "*** Additonal columns for FINAL =   $add_cols *** \n";

my $process_dng  = 0;
my $child_sample = "NA";
if ( defined $options{b} ) {
	$dng_vcf = $options{b};

	#&usage("DNG file not readable \n") unless (-s $dng_vcf);
	$process_dng = 1;

	#	if(not defined $options{pd}){
	#		&usage("Error! PED file required for DNG_v1.1 analysis... Aborted \n");
	#	}else{
	#		warn "Parsing child sample..\n";
	#		$child_sample = process_ped($options{pd});
	#		warn "Child = $child_sample\n";
	#	}
}

my $somatic = 0;
if ( defined $options{s} ) {
	if ( $options{s} == 0 || $options{s} == 1 ) {
		$somatic = $options{s};
	}
	else {
		warn " $options{s} : Wrong somatic (-s) flag! Assume germline..\n";
	}
}

my $log_dir = $work_dir;
if ( defined $options{l} ) {
	if ( not( -d $options{l} ) ) {
		&usage("$log_dir is invalid\n");
	}
	else {
		$log_dir = $options{l};
	}
}

my $sp_threshold = 15;
if ( defined $options{p} ) {
	$sp_threshold = $options{p};
}

my $neargene = 1000;
if ( defined $options{e} ) {
	impact $neargene = $options{e};
}

my $check_ref = "e";
if ( defined $options{cr} ) {
	$check_ref = $options{cr};
}

my $skip_norm = 0;
if ( defined $options{'sk'} ) {
	$skip_norm = 1;
	warn "*** Warning: skipping normalization\n";
}

my %ppr_pgm = (
	0   => 'NA',
	1   => 'GATK',
	2   => 'HAS',
	3.7 => 'EXOME_3.7',
	3   => 'EXOME-OLD',
	4   => 'OTHER',
	5   => 'Mssng'
);

my %in_types = (
	'mg' => 'mssng',
	'u'  => 'vcf',
	't'  => '1-based text (annovar)',
);

my $vcf2format = ".";
my @optional   = ();
my %arguments  = ();

my $type_ppr = 0;
if ( defined $options{c} ) {
	$type_ppr = $options{c};
	if ( !exists $ppr_pgm{$type_ppr} ) {
		&usage( "Invalid post-processing type(-c) value... allowed values are  "
			  . join( ",", sort ( keys %ppr_pgm ) ) );
	}
	if ( ( $in_file_type eq "m" ) && $type_ppr != 0 ) {
		warn "Post-processing available only for vcf inputs , resetting to 0\n";
		$type_ppr = 0;
	}
	if ( ( $in_file_type eq "t" ) && $type_ppr != 0 ) {
		warn "Post-processing available only for vcf inputs , resetting to 0\n";
		$type_ppr = 0;
	}

}

if ( ( $type_ppr == 3 || $type_ppr == 3.7 ) && !defined( $options{v} ) ) {

#usage("File type is exome, Coverage(dp) file is required! Use option -v to provide dp file!")
	warn
"** File type is exome, Coverage(dp) file is missing! Use option -v to provide dp file! Proceed without dp file **\n";
}
if ( ( $type_ppr == 3 || $type_ppr == 3.7 ) && !defined( $options{t} ) ) {

#usage("File type is exome, target bed file is required! Use option -t to provide dp file!")
	warn
"** File type is exome, target bed file is missing! Use option -t to provide dp file. Now proceeding without target bed file **  \n";
}

if ( $type_ppr == 3.7 || $type_ppr == 3 ) {
	warn
"** File type is exome.. Assume python/3.4.0 and other required modules are already loaded! **\n\n";
}

pod2usage(
	-verbose => 1,
	-exitval => 1,
	-output  => \*STDOUT,
	-message => "\n**input-file error**\n"
) unless ( -s $options{i} );
pod2usage(
	-verbose => 1,
	-exitval => 2,
	-output  => \*STDOUT,
	-message => "\n**Please specify config file**\n"
) unless ( defined $options{f} );
pod2usage(
	-verbose => 1,
	-exitval => 3,
	-output  => \*STDOUT,
	-message => "\n**specify input file types**\n"
) unless ( defined $options{m} );
pod2usage(
	-verbose => 1,
	-exitval => 4,
	-output  => \*STDOUT,
	-message => "\n**specify work dir**\n"
) unless ( defined $options{o} );

if ( not( -d $work_dir ) ) {
	&usage("work directory $work_dir is invalid");
}

my $input2go        = $input;
my $cginput         = $input;
my $input_basename  = basename($input);
my $input_basename0 = $input_basename;

my $d_gear = 0;
if ( defined $options{d} ) {
	$d_gear = $options{d};
}

my $pgx_vcf = 0;
if ( defined $options{x} ) {
	$pgx_vcf = 1;
	if ( $in_file_type ne "u" ) {
		usage(
"Input file ttpe error! Input is expected to be PGx vcf; This annotation only availale for vcf files (-m u).. exiting\n"
		);
	}
	my $out_pgx = $work_dir . "/" . $input_basename . "_pgx.vcf";
	my $count_fixpgx = validate_pgx( $input2go, $out_pgx );
	print STDOUT
	  "** $count_fixpgx ALT alleles are fixed for PGX analysis ** \n";
	$input2go = $out_pgx;
}

my $no_bgzip = 0;
if ( defined $options{q} ) {
	$no_bgzip = 1;
}

print STDOUT "Checking enviroments..\n";
check_loaded_modules();

my $vcfout = 0;
if ( defined $options{a} ) {
	$vcfout = 1;
	if ( $in_file_type ne "u" ) {
		usage(
"Input file type error! vcf-out is available only for vcf-input (-m u).. exiting\n"
		);
	}
}

my $table_only = 0;
if ( defined $options{T} ) {
	$table_only = 1;
}

my $sample2_vcf2tab = undef;
if ( defined $options{ST} ) {
	if ( not defined $options{T} ) {
		usage(
"sample subsetting (option --sample) is only available for vcf2tab function"
		);
	}
	else {
		$sample2_vcf2tab = $options{ST};
	}
}

warn "Sample2vcftab = $sample2_vcf2tab\n";

$no_hgmd = 0;
if ( defined $options{nh} ) {
	$no_hgmd = 1;
}

my @other_gene_opt = ();
if ( defined $options{hv} ) {
	push( @other_gene_opt, " --hgvs " );
}

if ( defined $options{es} ) {
	push( @other_gene_opt, " --exonicsplicing " );
}

my $run_type          = $options{m};
my $run_type_original = $run_type;

#for mssng tab
my $is_mssng = 0;
if ( $run_type_original eq "mg" ) {
	print STDOUT "Converting mssng input into vcf ...\n";
	$is_mssng    = 1;
	$calc_impact = 1;
	$no_hgmd     = 1;
	my $dummy_sample = $input_basename;
	$dummy_sample =~ s/-/_/g;
	$dummy_sample =~ s/vcf//g;
	$dummy_sample =~ s/\./_/g;

	my $mssng_rv    = MSSNG->new($input);
	my $mssng_vcfin = $log_dir . "/" . $input_basename . "_mssng.vcf";
	$mssng_rv->convert2vcf( $mssng_vcfin, $dummy_sample );
	$input2go          = $mssng_vcfin;
	$run_type          = "u";
	$run_type_original = "u";
	$original_input    = $mssng_vcfin;
}

#parsing config file
print STDOUT "Loading config file $config... \n";
my $fh_cfg      = IO::File->new( $config, q{<} ) or die "$! $config\n";
my %cfgs_detail = ();
my %cfgs        = ();
while ( my $line = <$fh_cfg> ) {
	chomp($line);
	if ( $line =~ m/#.+/ ) { }
	else {
		my $key     = ( split( "=",   $line ) )[0];
		my $value   = ( split( "=",   $line ) )[1];
		my $dbvalue = ( split( "\\|", $value ) )[0];
		$cfgs{$key}        = $dbvalue;
		$cfgs_detail{$key} = $value;
	}
}

my @config_errors_0 = ();
my $perl_home =
  ( exists $cfgs{perl_home} )
  ? $cfgs{perl_home}
  : push( @config_errors_0, "perl_home" );
if ( not( -f $perl_home ) ) {
	push( @config_errors_0, "perl_home : $perl_home not readale" );
}

my $annovar_home =
  ( exists $cfgs{annovar_home} )
  ? $cfgs{annovar_home}
  : push( @config_errors_0, "annovar_home" );
if ( not( -d $annovar_home ) ) {
	push( @config_errors_0, "annovar_home : $annovar_home not readale" );
}

my $tool_home = "$FindBin::Bin/../";

#build again
if ( not defined $options{BL} ) {
	$g_build =
	  ( exists $cfgs{build} )
	  ? $cfgs{build}
	  : usage("Cannot find build from config file");
	$pipeline_rev = "rev27.3" . "_" . $g_build;
	print "*** buld from config : $g_build , rev= $pipeline_rev ***\n";
}

#genome
my $cg_genome = -1;
$cg_genome = ( exists $cfgs{genome} ) ? $cfgs{genome} : -1;
my $vcf_genome = $cg_genome;
if ( defined $options{g} ) {
	$vcf_genome = $options{g};

	#$cg_genome = $options{g};
}

if ( ( scalar @config_errors_0 ) != 0 ) {
	my $cfg_error = join( "\n", @config_errors_0 );
	&usage( "Pipeline cannot continue due to following   issues in " 
		  . $config . "\n "
		  . $cfg_error );
}

my $sample_file = undef;

my $dng_info_file = $work_dir . "/" . $input_basename . ".dng.meta";

my $pipeline_stat = $log_dir . "/" . $input_basename . "_summary.txt";
if ( defined $options{ST} ) {
	$pipeline_stat =
	    $log_dir . "/"
	  . $input_basename . "_"
	  . $sample2_vcf2tab
	  . "_summary.txt";
}
open( SUM, ">$pipeline_stat" ) or die "$! $pipeline_stat\n";
my $this_time = localtime;
print SUM "**** $this_time ***** \n";
print SUM "\n>>Input summary:\n";
print SUM "Input file = $input\n";
my $in_file_type_desc =
  ( exists $in_types{$in_file_type} )
  ? $in_types{$in_file_type}
  : $in_file_type;
print SUM "File type = $in_file_type_desc\n";

if ( $run_type eq "m" ) {
	print STDOUT "run type = m , assume CG mastervar format\n";

	#preprocess mastervar .. taking only first 15 fields

	my $pr_master = $work_dir . "/" . $input_basename . "cut.tsv";

	#	my $tmp_dir = $base_dir . "/" . $tmp_directory . "/" ;
	my $pp_command =
	  "cut -f 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15 $input2go > $pr_master";
	print STDOUT "Preprocess mastervar:  $pp_command\n";
	print STDOUT "**mastervar-preprocessing  started\n";
	my $ex_st = system($pp_command);
	if ( $ex_st == 0 ) {
		print "**mastervar-preprocessing is finished  with exit code: $?\n";
	}
	else { usage("Critical error! mastervar-preprocessing is failed"); }

	$process_status_pre{'mastervar-preprocessing'}{command}     = $pp_command;
	$process_status_pre{'mastervar-preprocessing'}{exit_status} = $ex_st;
	push( @jobnames, "mastervar-preprocessing" );

	#convert mastervar to vcf
	my $vcf_in = $work_dir . "/" . $input_basename . ".vcf";
	my $mv_command =
"$tool_home\/scripts\/masterVar2VCFv41_rev2 $pr_master $cg_genome $vcf_in";
	print STDOUT "mastervar2Vcf:  $mv_command\n";
	print STDOUT "**mastervar2Vcf  started\n";
	my $ex_st = system($mv_command);
	if ( $ex_st == 0 ) {
		print STDOUT "** masterVar2Vcf is finished  with exit code: $?\n";
	}
	else { usage("Critical error! masterVar2Vcf failed"); }
	$process_status_pre{'masterVar2Vcf'}{command}     = $mv_command;
	$process_status_pre{'masterVar2Vcf'}{exit_status} = $ex_st;
	push( @jobnames, "masterVar2Vcf" );

	#reformat , add chr
	$input2go = $work_dir . "/" . $input_basename . ".chr.vcf";
	print STDOUT "**Reformating vcf file for vt ( adding chr)\n";
	my $ex_st = reformat_cg_vcf( $vcf_in, $input2go );
	$process_status_pre{'reformat_cg_vcf'}{command} =
	  "sub: reformat_cg_vcf\($vcf_in , $input2go\)";
	$process_status_pre{'reformat_cg_vcf'}{exit_status} = $ex_st;
	push( @jobnames, "reformat_cg_vcf" );

	#$input2go = $vcf_in;
	#decompose
	my $q1_o   = $work_dir . "/" . $input_basename . ".vt_decompose.out";
	my $q1_e   = $work_dir . "/" . $input_basename . ".vt_decompose.err";
	my $vt_out = $work_dir . "/" . $input_basename . ".decompose.vcf";
	print STDOUT "decompose-vcf\n";
	my $ex_st = decompose( $input2go, $vt_out, $q1_o, $q1_e );
	if ( $ex_st == 0 ) {
		print STDOUT "** Decompose-vcf is finished  with exit code: $?\n";
	}
	else {
		warn "Decompose-vcf is failed with exit code: $?\n";
		usage("Critical error! Decompose-vcf failed ( $q1_e )");
	}

	$process_status_pre{'Decompose-vcf'}{command} =
	  "sub: decompose\($input2go , $vt_out, $q1_o, $q1_e\)";
	$process_status_pre{'Decompose-vcf'}{exit_status} = $ex_st;
	push( @jobnames, "Decompose-vcf" );

	#normalize
	my $q1_o    = $work_dir . "/" . $input_basename . ".vt_norm.out";
	my $q1_e    = $work_dir . "/" . $input_basename . ".vt_norm.err";
	my $vtn_out = $work_dir . "/" . $input_basename . ".norm.vcf";
	print STDOUT "Normalize-vcf\n";
	my $ex_st = normalize( $vt_out, $vtn_out, $q1_o, $q1_e );
	if ( $ex_st == 0 ) {
		print STDOUT "** Normalize-vcf is finished  with exit code: $?\n";
	}
	else {
		warn "Normalize-vcf is failed with exit code: $?\n";
		usage("Critical error! normalize-vcf failed ( $q1_e )");
	}
	$process_status_pre{'Normalize-vcf'}{command} =
	  "sub: normalize\($vt_out,$vtn_out,$q1_o , $q1_e\)";
	$process_status_pre{'Normalize-vcf'}{exit_status} = $ex_st;
	push( @jobnames, "Normalize-vcf" );
	$input2go = $vtn_out;

}
elsif ( $run_type eq "u" ) {

	#multi-sample/single-sample vcf
	#sample subset, added Feb 4,2020
	if ( defined $options{ST} ) {
		my $smp_subset_out =
		  $work_dir . "/" . $input_basename . "_" . $sample2_vcf2tab . ".vcf";
		my $smp_subset_cmd =
		  "bcftools view -s $sample2_vcf2tab $input2go > $smp_subset_out";
		print STDOUT "$smp_subset_cmd\n";
		my $ex_st = system($smp_subset_cmd);
		if ( $ex_st == 0 ) {
			print STDOUT "** sample-subset is finished  with exit code: $?\n";
			$input2go       = $smp_subset_out;
			$input_basename = basename($input2go);
		}
		else {
			warn "sample-subset is failed with exit code: $?\n";
			usage("Critical: sample-subset is failed with exit code: $?");
		}

	}

	print STDOUT
"run type = u , assume vcf4.1 or vcf4.2 format ... Preprocessing vcf file...\n";
	if ( $process_dng == 1 ) {
		print STDOUT "Processing DNG vcf file also...\n";
	}
	my $file_path = $input2go;

	#extracting samples
	$sample_file = $work_dir . "/" . $input_basename . "_samples.txt";
	my $sample_command = " bcftools query -l  $input2go > $sample_file";
	print STDOUT "Parse sample_list: \n";
	print STDOUT "$sample_command\n";
	my $ex_st = system($sample_command);
	if ( $ex_st == 0 ) {
		print STDOUT "** sample-list is finished  with exit code: $?\n";
	}
	else {
		warn "sample-list is failed with exit code: $?\n";
		usage("Critical: sample-list is failed with exit code: $?");
	}
	$process_status_pre{'sample-list'}{command}     = $sample_command;
	$process_status_pre{'sample-list'}{exit_status} = $ex_st;
	push( @jobnames, "sample-list" );

	#extracting vcf header
	my $vcf_header   = $work_dir . "/" . $input_basename . "_vcfHeader.txt";
	my $vcfh_command = "bcftools view -h $input2go > $vcf_header";
	print STDOUT "get vcf header: \n";
	print STDOUT "$vcfh_command\n";
	my $ex_st = system($vcfh_command);
	if ( $ex_st == 0 ) {
		print STDOUT "** extract vcfheader is finished  with exit code: $?\n";
	}
	else {
		warn "extract vcfheader is failed with exit code: $?\n";
		usage("Critical:extract vcfheader is failed with exit code:  $?");
	}
	$process_status_pre{'vcfheader'}{command}     = $vcfh_command;
	$process_status_pre{'vcfheader'}{exit_status} = $ex_st;
	push( @jobnames, "vcfheader" );

	#preprocess vcf
	my $prep_vcf = $work_dir . "/" . $input_basename . ".prep.vcf";
	my $rv       = Vcfparse->new($input2go);
	print STDOUT "\nModule using:\n[";
	print STDOUT join( "\n", @INC ), "]\n\n";

	my $orig_count = $rv->add_orig_keys( $vcf_header, $prep_vcf );
	$process_status_pre{'add_orig_keys'}{command} =
	  "pm: Vcfparse::add_orig_keys\($vcf_header , $prep_vcf\)";
	$process_status_pre{'add_orig_keys'}{exit_status} = 0;
	$process_status_pre{'add_orig_keys'}{vcf_count}   = $orig_count;
	push( @jobnames, "add_orig_keys" );

	$input2go = $prep_vcf;
	if ( $run_type eq "u" ) {

		#decompose
		my $dcmpse_stat  = 0;
		my $dcmpse_total = 0;
		my $q1_o   = $work_dir . "/" . $input_basename . ".vt_decompose.out";
		my $q1_e   = $work_dir . "/" . $input_basename . ".vt_decompose.err";
		my $vt_out = $work_dir . "/" . $input_basename . ".decompose.vcf";
		print STDOUT "decompose-vcf:\n";
		my $ex_st = decompose( $prep_vcf, $vt_out, $q1_o, $q1_e );
		if ( $ex_st == 0 ) {
			print STDOUT "** Decompose-vcf is finished  with exit code: $?\n";
			my $dcmpse_err = `cat $q1_e`;
			if ( $dcmpse_err =~
m/Lines.+total\/split\/realigned\/skipped:\t(\d+)\/(\d+)\/(\d+)\/(\d+)/
			  )
			{
				$process_status_pre{'Decompose-vcf'}{total}        = $1;
				$process_status_pre{'Decompose-vcf'}{multi_allele} = $2;
				print SUM "\nDecomposed: $2\n";
			}
			else { warn "$dcmpse_err: Unexpected format!\n "; }
		}
		else {
			warn "Decompose-vcf is failed with exit code: $?\n";
			print "\n******************bcftools-error***********************\n";
			system("cat $q1_e");
			print "*****************************************\n";
			usage("Critical error! Decompose-vcf failed ( $q1_e )");
		}
		$process_status_pre{'Decompose-vcf'}{command} =
		  "sub: decompose\($prep_vcf , $vt_out , $q1_o , $q1_e\)";
		$process_status_pre{'Decompose-vcf'}{exit_status} = $ex_st;
		$process_status_pre{'Decompose-vcf'}{error_file}  = $q1_e;
		push( @jobnames, "Decompose-vcf" );

		#extracting vcf header
		my $vcf_header_dc =
		  $work_dir . "/" . $input_basename . "_vcfHeader.txt";
		my $vcfh_command = "bcftools view -h $vt_out > $vcf_header";
		print STDOUT "get vcf header for dc: \n";
		print STDOUT "$vcfh_command\n";
		my $ex_st = system($vcfh_command);
		if ( $ex_st == 0 ) {
			print STDOUT
			  "** extract vcfheader-dc is finished  with exit code: $?\n";
		}
		else {
			warn "extract vcfheader-dc is failed with exit code: $?\n";
			usage(
				"Critical:extract vcfheader-dc is failed with exit code:  $?");
		}
		$process_status_pre{'vcfheader-dc'}{command}     = $vcfh_command;
		$process_status_pre{'vcfheader-dc'}{exit_status} = $ex_st;
		push( @jobnames, "vcfheader-dc" );

		if ( $skip_norm == 0 ) {

			#normalize
			my $q1_o    = $work_dir . "/" . $input_basename . ".vt_norm.out";
			my $q1_e    = $work_dir . "/" . $input_basename . ".vt_norm.err";
			my $vtn_out = $work_dir . "/" . $input_basename . ".norm.vcf";
			print STDOUT "Normalize-vcf:\n";

			#hard-coded;
			my $compression_type = "v";
			my $ex_st =
			  normalize( $vt_out, $vtn_out, $q1_o, $q1_e, $pgx_vcf, $check_ref,
				$compression_type );
			if ( $ex_st == 0 ) {
				my $norm_err = `cat $q1_e`;
				if ( $norm_err =~
m/Lines.+total\/split\/realigned\/skipped:\t(\d+)\/(\d+)\/(\d+)\/(\d+)/
				  )
				{
					$process_status_pre{'Normalize-vcf'}{total}     = $1;
					$process_status_pre{'Normalize-vcf'}{realigned} = $3;
					print SUM "\nRealigned(normalized): $3\n";

				}
				else { warn "$norm_err: Unexpected format!\n "; }
			}
			else {
				warn "\nNormalize-vcf is failed with exit code: $?\n";
				print
				  "******************bcftools-error***********************\n";
				system("cat $q1_e");
				print "*****************************************\n";
				usage("Critical error! normalize-vcf failed ( $q1_e )");

			}
			$process_status_pre{'Normalize-vcf'}{command} =
			  "sub: normalize\($vt_out,$vtn_out,$q1_o , $q1_e\)";
			$process_status_pre{'Normalize-vcf'}{exit_status} = $ex_st;
			$process_status_pre{'Normalize-vcf'}{error_file}  = $q1_e;
			push( @jobnames, "Normalize-vcf" );
			$input2go = $vtn_out;

		   #index normalized file , added Mar2,2020
		   #			my $tabix_err = $work_dir . "/" . $input_basename . ".tabix.err";
		   #			my $tabix_cmd = "tabix $vtn_out 2>$tabix_err";
		   #			print STDOUT "Tabix: $tabix_cmd\n";
		   #			my $ex_st = system($tabix_cmd);
		   #			if($ex_st == 0){
		   #				warn "Tabix normalized_file done!\n"
		   #			}else{
		   #				warn "*** Tabix normalized_file failed! (OK)\n";
		   #			}
		   #	    	$process_status_pre{'tabix-norm'}{command} = $tabix_cmd;
		   #    		$process_status_pre{'tabix-norm'}{exit_status} = $ex_st;
		   #    		$process_status_pre{'tabix-norm'}{error_file} = $tabix_err;
		   #			push(@jobnames , "tabix-norm");

		}
		else {
			$input2go = $vt_out;
		}

		#added Sep13,2017 : Adding dp info, if exome 3.7
		my $dp1_o     = $work_dir . "/" . $input_basename . ".add_dp.out";
		my $dp1_e     = $work_dir . "/" . $input_basename . ".add_dp.err";
		my $dpvcf_out = $work_dir . "/" . $input_basename . ".norm.dp.vcf";
		my $dp_tmp    = $work_dir . "/" . $input_basename . "_dp_TEMP";
		my $dp_python_cmd =
"$dp_python_gagan ; python $dp_python -i $input2go -o $dpvcf_out -c $cov_file -t $dp_tmp > $dp1_e 2> $dp1_e";
		if ( ( $type_ppr == 3.7 || $type_ppr == 3 ) && defined $options{v} ) {
			system("mkdir -p $dp_tmp");
			print STDOUT "Add-dp\n";
			print STDOUT "$dp_python_cmd\n";
			$process_status_pre{'Add-dp'}{command} = $dp_python_cmd;
			my $dpex_st = system($dp_python_cmd);
			$process_status_pre{'Add-dp'}{exit_status} = $ex_st;
			if ( $dpex_st == 0 ) {
				print STDOUT "** Add-dp is finished  with exit code: $?\n";
				$input2go = $dpvcf_out;
			}
			else {
				warn "** Add-dp is finished  with exit code: $?\n";
				usage("Critical error! Add-dp failed ( $dp1_e )");
			}
		}

		#add dng info if available, added October 15,2019

		my $dng_annovar_in = "NA";

		if ( $process_dng == 1 ) {
			open( DMT, ">$dng_info_file" ) or die "$dng_info_file $!";
			warn "*** () Go DNG...\n";
			my %dng_meta = ();
			foreach my $this_dvcf ( split( ',', $dng_vcf ) ) {
				warn "dng = $this_dvcf\n";
				my ( $dng_smp, $out_dng ) =
				  process_DNG( $this_dvcf, $check_ref );
				chomp($dng_smp);
				chomp($out_dng);
				$dng_meta{$dng_smp} = $out_dng;
				warn "dng out = $out_dng, $dng_smp\n";
				print DMT $dng_smp, "\t", $out_dng, "\n";
			}
			close DMT;

		}

		#reformat
		print STDOUT "\nReformatting vcf by parsing different fields..\n";
		my $reformatted_vcf = $work_dir . "/" . $input_basename . "_ext.tsv";
		if ( $table_only == 1 ) {
			$reformatted_vcf = $log_dir . "/" . $input_basename . "_ext.tsv";
		}
		my $rv          = Vcfparse->new($input2go);
		my @info_fields = $rv->parse_INFO_fields();
		$process_status_pre{'parse_INFO_fields'}{command} =
		  "pm: Vcfparse::parse_INFO_fields\(\)";
		$process_status_pre{'parse_INFO_fields'}{exit_status} = 0;
		push( @jobnames, "parse_INFO_fields" );

		my @format_fields = $rv->parse_FORMAT_fields();
		$process_status_pre{'parse_FORMAT_fields'}{command} =
		  "pm: Vcfparse::parse_FORMAT_fields\(\)";
		$process_status_pre{'parse_FORMAT_fields'}{exit_status} = 0;
		push( @jobnames, "parse_FORMAT_fields" );

		my @vcfsamples = $rv->get_samples();
		$process_status_pre{'get_samples'}{command} =
		  "pm: Vcfparse::get_samples\(\)";
		$process_status_pre{'get_samples'}{exit_status} = 0;
		push( @jobnames, "get_samples" );

#my $rv_stat = $rv->reformat_vcf(join("," , @info_fields) , join("," , @format_fields) , $reformatted_vcf, $d_gear, $annovar_home);
		$vcf2format                = $input2go;
		$arguments{'vcf2format'}   = $vcf2format;
		$arguments{'summary-file'} = $pipeline_stat;

		my $rv_stat = undef;
		if ( $table_only == 1 ) {
			$rv_stat = $rv->reformat_vcf(
				join( ",", @info_fields ),
				join( ",", @format_fields ),
				$reformatted_vcf, $d_gear, $annovar_home, "NA"
			);
		}
		else {
			$rv_stat = $rv->reformat_vcf_simple(
				join( ",", @info_fields ),
				join( ",", @format_fields ),
				$reformatted_vcf, $d_gear, $annovar_home
			);
		}
		print STDOUT "**Processed variants = ", $rv_stat->{'var-counts'}, "\n";
		print STDOUT print Dumper($rv_stat), "\n";

		if ( $orig_count != $rv_stat->{'var-counts'} ) {
			usage(
"Critical: Orignal counts = $orig_count vs Processed_variants = ",
				$rv_stat->{'var-counts'}
			);
		}

		$process_status_pre{'reformat_vcf'}{command} =
"pm: Vcfparse::reformat_vcf\(<info_fields>, <format_fields>, <reformat-out>, <is-denovogear\?, 0 or 1> \)";
		$process_status_pre{'reformat_vcf'}{exit_status} = 0;
		$process_status_pre{'reformat_vcf'}{final_count} =
		  $rv_stat->{'var-counts'};
		push( @jobnames, "reformat_vcf" );

		$input2go = $reformatted_vcf;

	}
}

if ( $run_type eq "m" ) {
	print STDOUT "Convert to annovar format: \n";
	my $annovar_in = $work_dir . "/" . $input_basename . ".annovar.in.txt";
	my $q1_o       = $work_dir . "/" . $input_basename . ".cg2ann.out";
	my $q1_e       = $work_dir . "/" . $input_basename . ".cg2ann.err";
	my $q1_command =
"perl $annovar_home\/convert2annovar.pl -format vcf4 --allsample -include -withfreq -outfile $annovar_in $input2go > $q1_o 2> $q1_e";
	print STDOUT "$q1_command\n";
	my $ex_st = system($q1_command);
	if ( $ex_st == 0 ) {
		print STDOUT "*** convert2annovar is finished with exit code: $?\n";
	}
	else { usage("Critical error! convert2annovar failed"); }
	$process_status_pre{'convert2annovar'}{command}     = $q1_command;
	$process_status_pre{'convert2annovar'}{exit_status} = $ex_st;
	push( @jobnames, "convert2annovar" );

	print STDOUT "Adding extra fields to annovar-in file and annotating...\n";
	$input2go = $work_dir . "/" . $input_basename . ".cg.txt";
	extend_cg_annovar( $annovar_in, $cginput, $input2go );
	$run_type = "t";
	$process_status_pre{'add-cg'}{command} =
	  "sub: extend_cg_annovar\($annovar_in , $cginput , $input2go\)";
	$process_status_pre{'add-cg'}{exit_status} = 0;
	push( @jobnames, "add-cg" );
}

$this_time = localtime;
print STDOUT "\[$this_time\] Preprocessing finished..\n";
warn "final = $type_ppr\n";

#$arguments{'sample_file'} = $sample_file;
#$arguments{'log_dir'} = $log_dir;
#$arguments{'vcf_genome'} = $vcf_genome;
#$arguments{'cov_file'} = $cov_file;
#$arguments{'dng_vcf'} = $dng_vcf;
#$arguments{'somatic'} = $somatic;
#$arguments{'exome_target_bed'} = $ex_target_bed;
#$arguments{'keep_temp'} = $options{k};

if ( $run_type eq "u" ) {
	push( @optional, "-s $sample_file" );
	$arguments{'sample_file'} = $sample_file;
	$run_type = "t";

}
if ( defined $options{l} ) {
	push( @optional, "-l $log_dir" );
	$arguments{'log_dir'} = $log_dir;
}
if ( defined $options{g} ) {
	push( @optional, "-g $vcf_genome" );
	$arguments{'vcf_genome'} = $vcf_genome;
}
if ( defined $options{v} ) {
	push( @optional, "-y $cov_file" );
	$arguments{'cov_file'} = $cov_file;
}
if ( defined $options{b} ) {
	push( @optional, "-b $dng_vcf" );
	$arguments{'dng_vcf'}  = $dng_vcf;
	$arguments{'dng_file'} = 1;
	$arguments{'dng_meta'} = $dng_info_file;
}
else {
	$arguments{'dng_meta'} = "NA";
}

if ( defined $options{s} ) {
	push( @optional, "-n $somatic" );
	$arguments{'somatic'} = $somatic;
}

if ( defined $options{t} ) {
	push( @optional, "-t $ex_target_bed" );
	$arguments{'exome_target_bed'} = $ex_target_bed;
}

if ( defined $options{k} ) {
	push( @optional, "-k 1" );
	$arguments{'keep_temp'} = 1;
}

if ( defined $options{u} ) {
	push( @optional, "-u $out_format" );
	$arguments{'out_format'} = $out_format;
}

$arguments{'splicing_threshold'} = $sp_threshold;

#added oct3, 2016

$arguments{'input'}         = $input2go;
$arguments{'config'}        = $config;
$arguments{'type_ppr'}      = $type_ppr;
$arguments{'run_type'}      = $run_type;
$arguments{'work_dir'}      = $work_dir;
$arguments{'cores'}         = $cores;
$arguments{'org_input'}     = $original_input;
$arguments{'vcfout'}        = $vcfout;
$arguments{'run_type_orig'} = $run_type_original;
$arguments{'is_mssng'}      = $is_mssng;
$arguments{'no_hgmd'}       = $no_hgmd;
$arguments{'no_bgzip'}      = $no_bgzip;
$arguments{'neargene'}      = $neargene;
$arguments{'other-gene'}    = join( " ", @other_gene_opt );
$arguments{'impact'}        = 1;

my $appris_effect = 0;
$arguments{'appris-effect'} = 0;
my $appris_flags = "P1,P2,P3,P4,P5,ALT1,ALT2";
if ( defined $options{AP} ) {
	$appris_effect = 1;
	if ( -f $options{AP} ) {
		$arguments{'appris'}        = $options{AP};
		$arguments{'appris-effect'} = 1;
		if ( defined $options{PF} ) {
			$appris_flags = $options{PF};
		}
		$arguments{'appris-flags'} = $appris_flags;

	}
	else {
		usage( "Appris file Error! : ", $options{AP}, " is not readable!" );
	}
}

my $custom_gene = 0;

if ( defined $options{GF} ) {
	$custom_gene = 1;
	$arguments{'custom-genedef'} = $options{GF};
}
$arguments{'custom-gene'} = $custom_gene;
if ( defined $options{CG} ) {
	$arguments{'custom-genome'} = $options{CG};
}

#$arguments{'var-counts'} =  $rv_stat->{'var-counts'};

#my $pipeline_cmd = "$perl_home $tool_home\/scripts\/run_Annotation_level2_rev26.4.03.pl -i $input2go -f $config -c $type_ppr -m $run_type -o $work_dir -r $cores -s $sample_file -l $log_dir -g $vcf_genome -y $cov_file -b $dng_vcf ";
#my $pipeline_cmd = "$perl_home $tool_home\/scripts\/run_Annotation_level2_rev38.1.1.pl -i $input2go -f $config -c $type_ppr -m $run_type -o $work_dir -r $cores  " . join(" " , @optional); # -s $sample_file -l $log_dir -g $vcf_genome -y $cov_file -b $dng_vcf ";

print STDOUT "\nPipeline ready to Fly with following arguments: \n";
print STDOUT Dumper( \%arguments ), "\n";

if ( $table_only != 1 ) {
	my $pipeline_ext = run_annotation( \%arguments );
}

#print STDOUT "$pipeline_cmd\n";
#my $ex_st = system($pipeline_cmd);
#if ( $ex_st == 0 ) {
#
#	if($run_type eq "u"){
#		#post-process to do
#		print STDOUT "Pipeline finished with exit status 0\n";
#		warn "Pipeline finished with exit status 0\n";
#	}else{
#		print STDOUT "Pipeline finished with exit status 0\n";
#		warn "Pipeline finished with exit status 0\n";
#	}
#}
#else { die "Pipeline finished with error ( exit_status = $ex_st ) !\n"; }
#$process_status_pre{'Pipeline'}{command} = $pipeline_cmd;
#$process_status_pre{'Pipeline'}{exit_status} = $ex_st;
push( @jobnames, "Pipeline" );

#for new status , June 30,2016
my $monitor_out_pre = $log_dir . "/" . $input_basename . "_workflow.json";
my $ang =
  AnnotationEngine->new( \%process_status_pre, \@jobnames, $monitor_out_pre );
$ang->draw_workflow_json3();
close SUM;

#********END*****************#

#**************SUBROUTINES*********************************#

#output for help and errors
sub usage {
	my $error = shift;
	if ($error) {

		croak "\n\nERROR: $error\n\n";
	}
	else {

		#pod2usage();
		exit(-1);
	}
}

#decompose
sub decompose {
	my ( $inf, $outf, $out, $err ) = @_;

#bcftools norm -m-both -o Fre13-047.gatk.snp.indel.dc.vcf Fre13-047.gatk.snp.indel.vcf
#	my $q1_command =  "$vt_home decompose -o $outf $inf  > $out 2> $err";
	my $q1_command = "bcftools norm -m-both -o  $outf $inf  > $out 2> $err";
	print STDOUT "$q1_command\n";
	my $exit_st = system($q1_command);
	return $exit_st;
}

#normalize
sub normalize {
	my ( $inf, $outf, $out, $err, $ispgx, $chkref, $cmprs ) = @_;

#bcftools norm -f human_g1k_v37_decoy.fasta -o ex1.step2.vcf Fre13-047.gatk.snp.indel.vcf_TMP/Fre13-047.gatk.snp.indel.vcf.decompose.vcf
#my $q1_command =  "$vt_home normalize  -o $outf -r $vcf_genome -n $inf > $out 2> $err";
	warn "*** bcftools norm with --check-ref $chkref\n";
	my $q1_command =
"bcftools norm --check-ref $chkref -f $vcf_genome  -O $cmprs -o $outf $inf > $out 2> $err";
	if ( $ispgx == 1 ) {
		$q1_command =
		  "bcftools norm -cw -f $vcf_genome  -o $outf $inf > $out 2> $err";
	}
	print STDOUT "$q1_command\n";
	my $exit_st = system($q1_command);
	return $exit_st;
}

sub parse_INFO_fields {
	my ($vfile) = @_;
	my $fh_vfile = IO::File->new( $vfile, q{<} ) or die "$vfile $!";

	#open( TMPV, $vfile );
	my @infos = ();
	while ( my $line = <$fh_vfile> ) {
		chomp($line);
		if ( $line =~ m/^#CHROM/ ) { last; }
		else {

# ##INFO=<ID=NS,Number=1,Type=Integer,Description="Number of Samples With Data">
			if ( $line =~ m/^##INFO=.+ID=(.+?),.+/ ) {
				push( @infos, $1 );
			}

		}
	}
	close $fh_vfile->close();
	return @infos;
}

sub parse_FORMAT_fields {
	my ($vfile) = @_;

	#open( TMPV, $vfile );
	my $fh_vfile = IO::File->new( $vfile, q{<} ) or die "$vfile $!";
	my @infos = ();
	while ( my $line = <$fh_vfile> ) {
		chomp($line);
		if ( $line =~ m/^#CHROM/ ) { last; }
		else {

# ##INFO=<ID=NS,Number=1,Type=Integer,Description="Number of Samples With Data">
			if ( $line =~ m/^##FORMAT=.+ID=(.+?),.+/ ) {
				push( @infos, $1 );
			}

		}
	}
	close $fh_vfile->close();
	return @infos;
}

sub reformat_cg_vcf {
	my ( $org_cg_vcf, $out_cg_vcf ) = @_;

	#open(OCG, $org_cg_vcf) or die "$org_cg_vcf error\n";
	my $fh_ocg = IO::File->new( $org_cg_vcf, q{<} ) or die "$org_cg_vcf $!";

	#open(OCGO, ">$out_cg_vcf") or die "$out_cg_vcf error\n";
	my $fh_ocgo = IO::File->new( $out_cg_vcf, q{>} ) or die "$out_cg_vcf $!";

	while ( my $rline = <$fh_ocg> ) {
		chomp($rline);
		if ( $rline =~ m/^#/ ) {
			print $fh_ocgo $rline, "\n";
		}
		else {
			print $fh_ocgo "chr", $rline, "\n";
		}
	}
	$fh_ocg->close();
	$fh_ocgo->close();
	return 0;
}

sub extend_cg_annovar {
	my ( $org_cg_ann, $org_cg, $out_cg_ann ) = @_;

	#open(OCGA, $org_cg_ann) or die "$org_cg_ann error\n";
	my $fh_ocga = IO::File->new( $org_cg_ann, q{<} ) or die "$org_cg_ann $!";

	#open(OCG, $org_cg) or die "$org_cg error\n";
	my $fh_ocg = IO::File->new( $org_cg, q{<} ) or die "$org_cg $!";

	#open(OCGO, ">$out_cg_ann") or die "$out_cg_ann error\n";
	my $fh_ocgo = IO::File->new( $out_cg_ann, q{>} ) or die "$out_cg_ann $!";

	my %ocg       = ();
	my $cg_header = "#";
	while ( my $rline = <$fh_ocg> ) {
		chomp($rline);
		$rline =~ /^$/;
		$rline =~ /^#/ and next;
		if ( $rline =~ m/^>locus/ ) {
			$cg_header = $rline;
			$cg_header =~ s/>//;
		}
		else {
			my @fields = split( "\t", $rline );
			my $lcid = $fields[0];
			$ocg{$lcid} = $rline;
		}
	}
	close $fh_ocg->close;

	print $fh_ocgo "#chr\tstart\tend\tref\talt\t" . $cg_header, "\n";
	while ( my $rline = <$fh_ocga> ) {
		chomp($rline);
		my @fields = split( "\t", $rline );
		my $this_lcid = extract_locusid($rline);
		if ( exists $ocg{$this_lcid} ) {
			print $fh_ocgo $fields[0], "\t", $fields[1], "\t", $fields[2], "\t",
			  $fields[3], "\t", $fields[4], "\t", $ocg{$this_lcid}, "\n";
		}
		else {
			usage("Error extract cg info for locus id $this_lcid");
		}

	}

}

sub extract_locusid {
	my ($l) = @_;
	my $lc_id = 0;
	my $info = ( split( "\t", $l ) )[15];
	if ( $info =~ m/.+LO=(\d+)/ ) {
		$lc_id = $1;
	}
	return $lc_id;
}

sub trimVcf {
	my ( $invc, $outvc, $smp_file, $hdfile ) = @_;
	open( SMP, $smp_file ) or die "error $smp_file";
	my @samples = <SMP>;
	close SMP;
	chomp(@samples);
	my $total_cols = 9 + scalar(@samples);    # check
	open( INV, $invc )     or die "error $invc";
	open( INO, ">$outvc" ) or die "error $outvc";

	open( THD, $hdfile ) or die "$hdfile error\n";
	while ( my $hline = <THD> ) {
		chomp($hline);
		print INO $hline, "\n";
	}

	while ( my $rline = <INV> ) {
		chomp($rline);
		if ( $rline =~ m/^#/ ) {
			next;
		}
		else {
			my @getfields =
			  ( split( "\t", $rline ) )[ 0 .. ( $total_cols - 1 ) ];
			print INO join( "\t", @getfields ), "\n";
		}
	}
	close INO;
	close INV;
}

sub stichVcf {
	my ( $invc, $outvc, $org_vcf, $smp_file ) = @_;
	open( INV,  $invc )     or die "error $invc";
	open( INO,  ">$outvc" ) or die "error $outvc";
	open( INRV, $org_vcf )  or die "error $invc";
	open( SMP,  $smp_file ) or die "error $smp_file";
	my @samples = <SMP>;
	close SMP;
	my $total_cols = 9 + scalar(@samples);    # check
	chomp(@samples);
	my %inrv    = ();
	my @headers = ();

	while ( my $rline = <INRV> ) {
		chomp($rline);
		if ( $rline =~ m/^#/ ) {
			push( @headers, $rline );
		}
		else {
			my @rfields = split( "\t", $rline );
			my $key =
			    $rfields[0] . ":"
			  . $rfields[1] . ":"
			  . $rfields[3] . "/"
			  . $rfields[4];
			my @values = @rfields[ $total_cols .. ( scalar(@rfields) - 1 ) ];
			$inrv{$key} = join( "\t", @values );

			#			print $inrv{$key} , "\n";
		}
	}
	close INRV;
	print INO join( "\n", @headers ), "\n";
	while ( my $rline = <INV> ) {
		if ( $rline =~ m/^#/ ) { }
		else {
			chomp($rline);
			my @rfields = split( "\t", $rline );
			my $info_fld = $rfields[7];
			my $key =
			    $rfields[0] . ":"
			  . $rfields[1] . ":"
			  . $rfields[3] . "/"
			  . $rfields[4];
			if ( $info_fld =~ m/OLD_VARIANT=(.+)/ ) {
				$key = $1;
			}
			if ( exists $inrv{$key} ) {
				print INO $rline, "\t", $inrv{$key}, "\n";
			}
			else {
				die "Critical : vcf merge , missing values for $key\n";
			}
		}
	}
	close INV;
}

sub validate_params {
	my ($prms) = @_;

}

#updated to include v1.1, multiple probands

#updated to include v1.1, multiple probands
sub process_DNG_norm {
	my ( $dng_in, $ck_ref ) = @_;
	warn "*** DNG check ref = $check_ref\n";
	my $base_dng_in = basename($dng_in);

	#get sample name:
	my $this_dng_smp = `bcftools query -l $dng_in`;

	#extracting vcf header
	my $dng_vcf_header   = $work_dir . "/" . $base_dng_in . "_vcfHeader.txt";
	my $dng_vcfh_command = "bcftools view -h $dng_in > $dng_vcf_header";
	my $ex_st            = system($dng_vcfh_command);
	if ( $ex_st == 0 ) {
		print STDOUT
		  "** extract DNG vcfheader is finished  with exit code: $?\n";
	}
	else {
		warn "extract vcfheader is failed with exit code: $?\n";
		usage("Critical:extract vcfheader is failed with exit code:  $?");
	}
	$process_status_pre{'vcfheader_DNG'}{command}     = $dng_vcfh_command;
	$process_status_pre{'vcfheader_DNG'}{exit_status} = $ex_st;
	push( @jobnames, "vcfheader_DNG" );

	#	#preprocess dng vcf
	my $dng_prep_vcf = $dng_in;

#	my $dng_rv = Vcfparse->new($dng_in);
#	my $dng_orig_count = $dng_rv->add_orig_keys($dng_vcf_header , $dng_prep_vcf);
#	$process_status_pre{'add_orig_keys_DNG'}{command} = "pm: Vcfparse::add_orig_keys\(dng_header , $dng_prep_vcf\)";
#   $process_status_pre{'add_orig_keys_DNG'}{exit_status} = 0;
#   $process_status_pre{'add_orig_keys_DNG'}{vcf_count} = $dng_orig_count;
#	push(@jobnames , "add_orig_keys_DNG");

	#decompose
	my $dng_q1_o   = $work_dir . "/" . $base_dng_in . ".vt_decompose.out";
	my $dng_q1_e   = $work_dir . "/" . $base_dng_in . ".vt_decompose.err";
	my $dng_vt_out = $work_dir . "/" . $base_dng_in . ".decompose.vcf";
	print STDOUT "dng-decompose-vcf\n";
	my $ex_st = decompose( $dng_prep_vcf, $dng_vt_out, $dng_q1_o, $dng_q1_e );
	if ( $ex_st == 0 ) {
		print STDOUT "** DNG Decompose-vcf is finished  with exit code: $?\n";

#			my $dcmpse_err = `cat $q1_e`;
#			if($dcmpse_err =~ m/Lines.+total\/split\/realigned\/skipped:\t(\d+)\/(\d+)\/(\d+)\/(\d+)/){
#				$process_status_pre{'Decompose-vcf'}{total} = $1;
#				$process_status_pre{'Decompose-vcf'}{multi_allele} = $2;
#			}else{ warn "$dcmpse_err: Unexpected format!\n ";}
	}
	else {
		warn "DNG Decompose-vcf is failed with exit code: $?\n";
		usage("Critical error! DNG Decompose-vcf failed ( $dng_q1_e )");
	}
	$process_status_pre{'Decompose-vcf-dng'}{command} =
	  "sub: decompose\($dng_prep_vcf , $dng_vt_out , $dng_q1_o , $dng_q1_e\)";
	$process_status_pre{'Decompose-vcf-dng'}{exit_status} = $ex_st;
	push( @jobnames, "Decompose-vcf-dng" );

	#normalize
	my $dng_q1_o    = $work_dir . "/" . $base_dng_in . ".vt_norm.out";
	my $dng_q1_e    = $work_dir . "/" . $base_dng_in . ".vt_norm.err";
	my $dng_vtn_out = $work_dir . "/" . $base_dng_in . ".norm.vcf";
	print STDOUT "DNG Normalize-vcf with chkref = $ck_ref\n";
	my $ex_st =
	  normalize( $dng_vt_out, $dng_vtn_out, $dng_q1_o, $dng_q1_e, 0, $ck_ref );
	if ( $ex_st == 0 ) {
		print STDOUT "** DNG Normalize-vcf is finished  with exit code: $?\n";

#			my $norm_err = `cat $q1_e`;
#			if($norm_err =~ m/Lines.+total\/split\/realigned\/skipped:\t(\d+)\/(\d+)\/(\d+)\/(\d+)/){
#				$process_status_pre{'Normalize-vcf'}{total} = $1;
#				$process_status_pre{'Normalize-vcf'}{realigned} = $2;
#			}else{ warn "$norm_err: Unexpected format!\n ";}
	}
	else {
		warn "DNG Normalize-vcf is failed with exit code: $?\n";
		usage("Critical error! DNG normalize-vcf failed ( $dng_q1_e )");
	}
	$process_status_pre{'Normalize-vcf-dng'}{command} =
"sub: normalize\($dng_vt_out,$dng_vtn_out,$dng_q1_o , $dng_q1_e, $ck_ref\)";
	$process_status_pre{'Normalize-vcf-dng'}{exit_status} = $ex_st;
	push( @jobnames, "Normalize-vcf-dng" );
}

sub process_DNG {
	my ( $dng_in, $ck_ref ) = @_;
	warn "*** DNG check ref = $check_ref\n";
	my $base_dng_in = basename($dng_in);

	#get sample name:
	my $this_dng_smp = `bcftools query -l $dng_in`;

	#extracting vcf header
	my $dng_vcf_header   = $work_dir . "/" . $base_dng_in . "_vcfHeader.txt";
	my $dng_vcfh_command = "bcftools view -h $dng_in > $dng_vcf_header";
	my $ex_st            = system($dng_vcfh_command);
	if ( $ex_st == 0 ) {
		print STDOUT
		  "** extract DNG vcfheader is finished  with exit code: $?\n";
	}
	else {
		warn "extract vcfheader is failed with exit code: $?\n";
		usage("Critical:extract vcfheader is failed with exit code:  $?");
	}
	$process_status_pre{'vcfheader_DNG'}{command}     = $dng_vcfh_command;
	$process_status_pre{'vcfheader_DNG'}{exit_status} = $ex_st;
	push( @jobnames, "vcfheader_DNG" );

	#	#preprocess dng vcf
	my $dng_prep_vcf = $dng_in;

#	my $dng_rv = Vcfparse->new($dng_in);
#	my $dng_orig_count = $dng_rv->add_orig_keys($dng_vcf_header , $dng_prep_vcf);
#	$process_status_pre{'add_orig_keys_DNG'}{command} = "pm: Vcfparse::add_orig_keys\(dng_header , $dng_prep_vcf\)";
#   $process_status_pre{'add_orig_keys_DNG'}{exit_status} = 0;
#   $process_status_pre{'add_orig_keys_DNG'}{vcf_count} = $dng_orig_count;
#	push(@jobnames , "add_orig_keys_DNG");

	#decompose
	my $dng_q1_o   = $work_dir . "/" . $base_dng_in . ".vt_decompose.out";
	my $dng_q1_e   = $work_dir . "/" . $base_dng_in . ".vt_decompose.err";
	my $dng_vt_out = $work_dir . "/" . $base_dng_in . ".decompose.vcf";
	print STDOUT "dng-decompose-vcf\n";
	my $ex_st = decompose( $dng_prep_vcf, $dng_vt_out, $dng_q1_o, $dng_q1_e );
	if ( $ex_st == 0 ) {
		print STDOUT "** DNG Decompose-vcf is finished  with exit code: $?\n";

#			my $dcmpse_err = `cat $q1_e`;
#			if($dcmpse_err =~ m/Lines.+total\/split\/realigned\/skipped:\t(\d+)\/(\d+)\/(\d+)\/(\d+)/){
#				$process_status_pre{'Decompose-vcf'}{total} = $1;
#				$process_status_pre{'Decompose-vcf'}{multi_allele} = $2;
#			}else{ warn "$dcmpse_err: Unexpected format!\n ";}
	}
	else {
		warn "DNG Decompose-vcf is failed with exit code: $?\n";
		usage("Critical error! DNG Decompose-vcf failed ( $dng_q1_e )");
	}
	$process_status_pre{'Decompose-vcf-dng'}{command} =
	  "sub: decompose\($dng_prep_vcf , $dng_vt_out , $dng_q1_o , $dng_q1_e\)";
	$process_status_pre{'Decompose-vcf-dng'}{exit_status} = $ex_st;
	push( @jobnames, "Decompose-vcf-dng" );

	#normalize
	my $dng_q1_o    = $work_dir . "/" . $base_dng_in . ".vt_norm.out";
	my $dng_q1_e    = $work_dir . "/" . $base_dng_in . ".vt_norm.err";
	my $dng_vtn_out = $work_dir . "/" . $base_dng_in . ".norm.vcf";
	print STDOUT "DNG Normalize-vcf with chkref = $ck_ref\n";
	my $ex_st =
	  normalize( $dng_vt_out, $dng_vtn_out, $dng_q1_o, $dng_q1_e, 0, $ck_ref );
	if ( $ex_st == 0 ) {
		print STDOUT "** DNG Normalize-vcf is finished  with exit code: $?\n";

#			my $norm_err = `cat $q1_e`;
#			if($norm_err =~ m/Lines.+total\/split\/realigned\/skipped:\t(\d+)\/(\d+)\/(\d+)\/(\d+)/){
#				$process_status_pre{'Normalize-vcf'}{total} = $1;
#				$process_status_pre{'Normalize-vcf'}{realigned} = $2;
#			}else{ warn "$norm_err: Unexpected format!\n ";}
	}
	else {
		warn "DNG Normalize-vcf is failed with exit code: $?\n";
		usage("Critical error! DNG normalize-vcf failed ( $dng_q1_e )");
	}
	$process_status_pre{'Normalize-vcf-dng'}{command} =
"sub: normalize\($dng_vt_out,$dng_vtn_out,$dng_q1_o , $dng_q1_e, $ck_ref\)";
	$process_status_pre{'Normalize-vcf-dng'}{exit_status} = $ex_st;
	push( @jobnames, "Normalize-vcf-dng" );

	#reformat dng
	print STDOUT "reformatting dng vcf by parsing different fields..\n";
	my $dng_reformatted_vcf = $work_dir . "/" . $base_dng_in . "_ext.tsv";
	my $dng_rv              = Vcfparse->new($dng_vtn_out);
	my @dng_info_fields     = $dng_rv->parse_INFO_fields();
	$process_status_pre{'parse_INFO_fields-dng'}{command} =
	  "pm: Vcfparse::parse_INFO_fields\(\)";
	$process_status_pre{'parse_INFO_fields-dng'}{exit_status} = 0;
	push( @jobnames, "parse_INFO_fields-dng" );

	my @dng_format_fields = $dng_rv->parse_FORMAT_fields();
	$process_status_pre{'parse_FORMAT_fields-dng'}{command} =
	  "pm: Vcfparse::parse_FORMAT_fields\(\)";
	$process_status_pre{'parse_FORMAT_fields-dng'}{exit_status} = 0;
	push( @jobnames, "parse_FORMAT_fields-dng" );

	my @dng_vcfsamples = $dng_rv->get_samples();
	$process_status_pre{'get_samples-dng'}{command} =
	  "pm: Vcfparse::get_samples\(\)";
	$process_status_pre{'get_samples-dng'}{exit_status} = 0;
	push( @jobnames, "get_samples-dng" );

#my $rv_stat = $rv->reformat_vcf(join("," , @info_fields) , join("," , @format_fields) , $reformatted_vcf, $d_gear, $annovar_home);
	$dng_rv->reformat_vcf_dng(
		join( ",", @dng_info_fields ),
		join( ",", @dng_format_fields ),
		$dng_reformatted_vcf, 1
	);
	$process_status_pre{'reformat_vcf-dng'}{command} =
"pm: Vcfparse::reformat_vcf_dng\(<info_fields>, <format_fields>, <reformat-out>, <is-denovogear\?, 1  \) ";
	$process_status_pre{'reformat_vcf-dng'}{exit_status} = 0;
	push( @jobnames, "reformat_vcf-dng" );

	warn "**DNG out = $dng_reformatted_vcf\n";

	#Convert annovar
	print STDOUT "DNG Convert to annovar format: \n";
	my $dng_annovar_in = $work_dir . "/" . $base_dng_in . ".annovar.in.txt";
	my $dng_q1_o       = $work_dir . "/" . $base_dng_in . ".cg2ann.out";
	my $dng_q1_e       = $work_dir . "/" . $base_dng_in . ".cg2ann.err";
	warn "** annovar = $annovar_home\n";
	my $dng_q1_command =
"perl $annovar_home\/convert2annovar.pl -format vcf4old  -include -comment -outfile $dng_annovar_in $dng_reformatted_vcf > $dng_q1_o 2> $dng_q1_e";
	print STDOUT "$dng_q1_command\n";
	my $ex_st = system($dng_q1_command);

	if ( $ex_st == 0 ) {
		print STDOUT "*** DNG-convert2annovar is finished with exit code: $?\n";
	}
	else { usage("Critical error! DNG-convert2annovar failed"); }

	#make annovar_filter_db
	my $dng_out =
	  make_annovar_filter_db( $dng_annovar_in, $base_dng_in, $work_dir );
	print STDOUT "Generated db files = $dng_out \n";

#		#bedop sort region file
#		my $sorted_db_bed_file = $work_dir . "/hg19_" . $base_dng_in . ".bed";
#		my $bed_sort_cmd = "sort-bed $dng_bed_out > $sorted_db_bed_file";
#		my $ex_st = system($bed_sort_cmd);
#		if($ex_st == 0 ) { print STDOUT "*** sort-bed finished with exit code: $?\n";} else { usage("Critical error! sort-bed failed for $dng_bed_out");}

	return ( $this_dng_smp, $dng_reformatted_vcf );

}

sub make_annovar_filter_db {
	my ( $fl, $prefix ) = @_;
	open( FL, $fl ) or die "$!";
	my $db_file = $work_dir . "/hg19_" . $prefix . ".txt";

	#my $db_bed = $work_dir . "/hg19_" . $prefix . "_usort.bed";
	open( OFL, ">$db_file" ) or die "$!";

	#open(OFD, ">$db_bed") or die "$!";
	my $db_header = <FL>;
	chomp($db_header);
	my @db_names   = ();
	my %header_idx = ();
	my $idx        = 0;
	foreach my $dbn ( split( "\t", $db_header ) ) {
		$header_idx{$dbn} = $idx + 5;
		if ( $idx >= 10 ) {
			push( @db_names, $dbn );
		}
		$idx++;
	}
	print OFL "#chr\tstart\tend\tref\talt\t" . join( ",", @db_names ), "\n";

	#print OFD "#chr\tstart\tend\t" . join("," , @db_names) , "\n";

	while ( my $line = <FL> ) {
		chomp($line);
		my @db_fields = split( "\t", $line );
		my @outs = ();
		foreach my $dbn (@db_names) {
			my $index_of_db =
			  ( exists $header_idx{$dbn} )
			  ? $header_idx{$dbn}
			  : die "$dbn index error\n";
			push( @outs, $db_fields[ $header_idx{$dbn} ] );
		}

		my $bed_key =
		    $db_fields[0] . ":"
		  . $db_fields[1] . ":"
		  . $db_fields[2] . ":"
		  . $db_fields[3] . ":"
		  . $db_fields[4];
		print OFL $db_fields[0], "\t", $db_fields[1], "\t", $db_fields[2], "\t",
		  $db_fields[3], "\t", $db_fields[4], "\t", join( ",", @outs ), "\n";

#print OFD $db_fields[0] , "\t" , ($db_fields[1] - 1) , "\t" , $db_fields[2] , "\t" ,   join("," , @outs) , "\t" , $bed_key , "\n" ;
	}
	close OFL;

	#close OFD;
	return $db_file;
}

sub validate_pgx {
	my ( $in_vcf, $out_pgx_vcf ) = @_;
	my $count_fixed = 0;
	my $fh_ivcf     = undef;

	if ( $in_vcf =~ /\.gz$/ ) {
		warn "gzipped PGx vcf file\n";
		open( $fh_ivcf, "gunzip -c $in_vcf |" )
		  || die "cant open pipe to $in_vcf";

#$fh_vcf = IO::File->new("gunzip -c $vcffile |" , q{<}) or usage("$! cannnot load input vcf $vcffile\n");
	}
	else {
		warn "Plain PGx vcf file..\n";
		$fh_ivcf = IO::File->new( $in_vcf, q{<} ) or die "$in_vcf $!";
	}

	#my $fh_ivcf = IO::File->new($in_vcf , q{<}) or die "$in_vcf $!";
	my $fh_outpgx = IO::File->new( $out_pgx_vcf, q{>} )
	  or die "$out_pgx_vcf $!";
	while ( my $line = <$fh_ivcf> ) {
		chomp($line);
		if ( $line =~ m/^#/ ) {
			print $fh_outpgx $line, "\n";
		}
		else {
			my @pgx_fields = split( "\t", $line );
			my @outline = @pgx_fields;
			if ( $pgx_fields[4] eq "." ) {
				$count_fixed++;
				$outline[4] = $pgx_fields[3];
			}
			print $fh_outpgx join( "\t", @outline ), "\n";
		}
	}
	close $fh_outpgx;
	close $fh_ivcf;
	return $count_fixed;
}

#main run $output_cfg_file
sub run_annotation {
	my $run_arg          = shift;
	my $run_input        = $run_arg->{'input'};
	my $run_config       = $run_arg->{'config'};
	my $run_in_file_type = $run_arg->{'run_type'};
	my $run_work_dir     = $run_arg->{'work_dir'};
	my $run_cores        = $run_arg->{'cores'};
	my $run_cov_file     = $run_arg->{'cov_file'};
	my $run_dng_file     = $run_arg->{'dng_file'};
	my $run_dng_meta     = $run_arg->{'dng_meta'};

	my $run_vcf_genome = $run_arg->{'vcf_genome'};

	my $run_ex_target_bed = $run_arg->{'exome_target_bed'};
	my $run_keep_full     = $run_arg->{'keep_temp'};
	my $run_orginal_input = $run_arg->{'org_input'};
	my $isvcfout          = $run_arg->{'vcfout'};
	my $run_type_original = $run_arg->{'run_type_orig'};
	my $run_is_mssng      = $run_arg->{'is_mssng'};
	my $run_no_hgmd       = $run_arg->{'no_hgmd'};
	my $sp_threshold      = $run_arg->{'splicing_threshold'};
	my $neargene          = $run_arg->{'neargene'};
	my $no_bgzip          = $run_arg->{'no_bgzip'};
	my $vcf2format        = $run_arg->{'vcf2format'};

	#my $vcf2format = $run_arg->{'vcf2format'};
	my $summ_file    = $run_arg->{'summary-file'};
	my $add_gene_opt = $run_arg->{'other-gene'};

	#$arguments{'impact'}
	my $run_calc_impact = $run_arg->{'impact'};

	#		$arguments{'appris'} = $options{AP};
	#		$arguments{'appris-effect'} = 1;

	my $run_appris_effect = $run_arg->{'appris-effect'};
	my $run_appris_db     = $run_arg->{'appris'};
	my $run_appris_flags  = $run_arg->{'appris-flags'};

	#my $total_input = $run_arg->{'var-counts'};

	#$arguments{'custom-gene'}
	my $run_cus_gene    = $run_arg->{'custom-gene'};
	my $run_cus_genedef = $run_arg->{'custom-genedef'};

	my %annovar_gene_module   = ();
	my %annovar_filter_module = ();
	my %annovar_region_module = ();
	my %bedops_region_module  = ();
	my %bedops_filter_module  = ();
	my %bedops_closest_module = ();

	my $run_log_dir =
	  ( exists $run_arg->{'log_dir'} ) ? $run_arg->{'log_dir'} : $run_work_dir;
	if ( not( -d $run_log_dir ) ) {
		pod2usage(
			-verbose => 1,
			-exitval => 5,
			-output  => \*STDOUT,
			-message => "\n**$run_log_dir is invalid**\n"
		);
	}

	my $somatic = ( exists $run_arg->{'somatic'} ) ? 1 : 0;

	#for final post-processing , added Aprl 29, 2016

	my %ppr_pgm = (
		0   => 'NA',
		1   => 'GATK',
		2   => 'HAS',
		3   => 'EXOM',
		3.7 => 'EXOM_3.7',
		4   => 'OTHER',
		5   => 'Mssng'
	);

	my $run_type_ppr =
	  ( exists $run_arg->{'type_ppr'} ) ? $run_arg->{'type_ppr'} : 0;

	if ( !exists $ppr_pgm{$run_type_ppr} ) {
		my $pod_msg =
		  "In post-processing type(-c) value... allowed values are  "
		  . join( ",", sort ( keys %ppr_pgm ) );
		pod2usage(
			-verbose => 1,
			-exitval => 5,
			-output  => \*STDOUT,
			-message => "\n** $pod_msg **\n"
		);
	}
	if ( ( $run_in_file_type eq "m" || $run_in_file_type eq "v" )
		&& $run_type_ppr != 0 )
	{
		warn "Post-processing available only for vcf inputs , resetting to 0\n";
		$run_type_ppr = 0;
	}

	if ( $run_type_ppr == 0 ) {
		$run_keep_full = 1;
	}

	my $vcf_smp_file =
	  ( exists $run_arg->{'sample_file'} ) ? $run_arg->{'sample_file'} : undef;

	#double checking..
	pod2usage(
		-verbose => 1,
		-exitval => 255,
		-output  => \*STDOUT,
		-message => "\n**Input file is not readable..**\n"
	) unless ( -s $run_input );
	pod2usage(
		-verbose => 1,
		-exitval => 255,
		-output  => \*STDOUT,
		-message => "\n**Please specify config file.. **\n"
	) unless ( -s $run_config );
	pod2usage(
		-verbose => 1,
		-exitval => 5,
		-output  => \*STDOUT,
		-message => "\n**Please specify input file type.. **\n"
	) unless ( exists $run_arg->{'run_type'} );
	pod2usage(
		-verbose => 1,
		-exitval => 5,
		-output  => \*STDOUT,
		-message => "\n**Invalid work directory $run_work_dir.. **\n"
	) unless ( -d $run_work_dir );

	my $no_of_jobs = 0;
	my @job_names  = ();

	my $build = $cfgs{build};

	my %db_versions        = ();
	my %db_versions_pg     = ();
	my %db_versions_gene   = ();
	my %db_versions_pheno  = ();
	my %db_versions_filter = ();
	my %db_versions_region = ();

	my @config_errors = ();
	my $perl_home =
	  ( exists $cfgs{perl_home} )
	  ? $cfgs{perl_home}
	  : push( @config_errors, "perl_home" );

	#my $vt_home = (exists $cfgs{vt}) ? $cfgs{vt} : push(@config_errors, "vt");

	my $tool_home = "$FindBin::Bin/../";
	if ( not( -d $tool_home ) ) {
		push( @config_errors, "tool_home : $tool_home not readale" );
	}
	my $annovar_home =
	  ( exists $cfgs{annovar_home} )
	  ? $cfgs{annovar_home}
	  : push( @config_errors, "annovar_home" );
	if ( not( -d $annovar_home ) ) {
		push( @config_errors, "annovar_home : $annovar_home not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{'annovar_home'};
		$db_versions{'programs'}{'annovar'} = ( split( '\|', $db_detail ) )[1];
	}

	my $annovar_gene_db =
	  ( exists $cfgs{annovar_gene_db} )
	  ? $cfgs{annovar_gene_db}
	  : push( @config_errors, "annovar_gene_db" );
	if ( not( -d $annovar_gene_db ) ) {
		push( @config_errors,
			"annovar_gene_db  : $annovar_gene_db not readale" );
	}

	my $annovar_ext_db =
	  ( exists $cfgs{annovar_ext_db} )
	  ? $cfgs{annovar_ext_db}
	  : push( @config_errors, "annovar_ext_db" );
	if ( not( -d $annovar_ext_db ) ) {
		push( @config_errors, "annovar_ext_db  : $annovar_ext_db not readale" );
	}

	my $filter_dbsnp =
	  ( exists $cfgs{filter_dbsnp} )
	  ? $cfgs{filter_dbsnp}
	  : push( @config_errors, "filter_dbsnp" );
	my $loc = $annovar_ext_db . "/" . $build . "_" . $filter_dbsnp . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_dbsnp : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{filter_dbsnp};
		$db_versions{'DbSNP'}{'dbsnp'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'dbsnp'}{db} = $filter_dbsnp;
	}

	my $filter_dbsnpCommon =
	  ( exists $cfgs{filter_dbsnpCommon} )
	  ? $cfgs{filter_dbsnpCommon}
	  : push( @config_errors, "filter_dbsnpCommon" );
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $filter_dbsnpCommon . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_dbsnpCommon : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_dbsnpCommon'};
		$db_versions{'DbSNP'}{'dbsnpCommon'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'dbsnpCommon'}{db} = $filter_dbsnpCommon;
	}

	my $filter_clinvar =
	  ( exists $cfgs{filter_clinvar} )
	  ? $cfgs{filter_clinvar}
	  : push( @config_errors, "filter_clinvar" );
	my $loc = $annovar_ext_db . "/" . $build . "_" . $filter_clinvar . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_clinvar : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_clinvar'};
		$db_versions{'Clinvar'}{'clinvar'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'clinvar'}{db} = $filter_clinvar;
	}

	my $filter_thg =
	  ( exists $cfgs{filter_thg} )
	  ? $cfgs{filter_thg}
	  : push( @config_errors, "filter_thg" );
	my $thgall_file_prefix = check_1000g_db($filter_thg);
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $thgall_file_prefix . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_1000g : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_thg'};
		$db_versions{'Filter'}{'1000g'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'1000g'}{db}        = $filter_thg;
		$annovar_filter_module{'1000g'}{db_prefix} = $thgall_file_prefix;
	}

	my $filter_thg_asn =
	  ( exists $cfgs{filter_thg_asn} )
	  ? $cfgs{filter_thg_asn}
	  : push( @config_errors, "filter_thg_asn" );
	my $thgasn_file_prefix = check_1000g_db($filter_thg_asn);
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $thgasn_file_prefix . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_1000g_EAS : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_thg_asn'};
		$db_versions{'Filter'}{'1000g_EAS'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'1000g_EAS'}{db}        = $filter_thg_asn;
		$annovar_filter_module{'1000g_EAS'}{db_prefix} = $thgasn_file_prefix;
	}

	my $filter_thg_afr =
	  ( exists $cfgs{filter_thg_afr} )
	  ? $cfgs{filter_thg_afr}
	  : push( @config_errors, "filter_thg_afr" );
	my $thgafr_file_prefix = check_1000g_db($filter_thg_afr);
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $thgafr_file_prefix . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_1000g_AFR : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_thg_afr'};
		$db_versions{'Filter'}{'1000g_AFR'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'1000g_AFR'}{db}        = $filter_thg_afr;
		$annovar_filter_module{'1000g_AFR'}{db_prefix} = $thgafr_file_prefix;
	}

	my $filter_thg_amr =
	  ( exists $cfgs{filter_thg_amr} )
	  ? $cfgs{filter_thg_amr}
	  : push( @config_errors, "filter_thg_amr" );
	my $thgamr_file_prefix = check_1000g_db($filter_thg_amr);
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $thgamr_file_prefix . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_1000g_AMR : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_thg_amr'};
		$db_versions{'Filter'}{'1000g_AMR'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'1000g_AMR'}{db}        = $filter_thg_amr;
		$annovar_filter_module{'1000g_AMR'}{db_prefix} = $thgamr_file_prefix;
	}

	my $filter_thg_eur =
	  ( exists $cfgs{filter_thg_eur} )
	  ? $cfgs{filter_thg_eur}
	  : push( @config_errors, "filter_thg_eur" );
	my $thgeur_file_prefix = check_1000g_db($filter_thg_eur);
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $thgeur_file_prefix . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_1000g_EUR : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_thg_eur'};
		$db_versions{'Filter'}{'1000g_EUR'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'1000g_EUR'}{db}        = $filter_thg_eur;
		$annovar_filter_module{'1000g_EUR'}{db_prefix} = $thgeur_file_prefix;
	}

	my $filter_thg_sas =
	  ( exists $cfgs{filter_thg_sas} )
	  ? $cfgs{filter_thg_sas}
	  : push( @config_errors, "filter_thg_sas" );
	my $thgsas_file_prefix = check_1000g_db($filter_thg_sas);
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $thgsas_file_prefix . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_1000g_SAS : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_thg_sas'};
		$db_versions{'Filter'}{'1000g_SAS'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'1000g_SAS'}{db_prefix} = $thgsas_file_prefix;
		$annovar_filter_module{'1000g_SAS'}{db}        = $filter_thg_sas;
	}

	my $filter_NHLBI_exac =
	  ( exists $cfgs{filter_NHLBI_exac} )
	  ? $cfgs{filter_NHLBI_exac}
	  : push( @config_errors, "filter_NHLBI_exac" );
	my $loc =
	  $annovar_ext_db . "/" . $build . "_" . $filter_NHLBI_exac . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_NHLBI_exac : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_NHLBI_exac'};
		$db_versions{'Filter'}{'exac'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'exac'}{db} = $filter_NHLBI_exac;
	}

	#	#gnomeAD_dir
	my $gnAD_dir =
	  ( exists $cfgs{gnomeAD_dir} )
	  ? $cfgs{gnomeAD_dir}
	  : push( @config_errors, "gnomeAD_dir" );
	my $filter_gnAD_ex =
	  ( exists $cfgs{filter_gnomad_exome} )
	  ? $cfgs{filter_gnomad_exome}
	  : push( @config_errors, "filter_gnomad_exome" );
	my $loc = $gnAD_dir . "/" . $build . "_" . $filter_gnAD_ex . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_gnomad_exome : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_gnomad_exome'};
		$db_versions{'Filter'}{'gnomad_exome211'} =
		  ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'gnomad_exome211'}{db}     = $filter_gnAD_ex;
		$annovar_filter_module{'gnomad_exome211'}{db_dir} = $gnAD_dir;
	}

#	my @gnomAD_chr = 1 .. 22;
#	push(@gnomAD_chr , "X");
#	my $filter_gnAD_gn = (exists $cfgs{filter_gnomad_genome}) ?  $cfgs{filter_gnomad_genome} : push(@config_errors, "filter_gnomad_genome");
#	my $filter_gnAD_gn211 = (exists $cfgs{filter_gnomad_genome211}) ?  $cfgs{filter_gnomad_genome211} : push(@config_errors, "filter_gnomad_genome211");
#
#	my $loc = $gnAD_dir .  "/" . $build . "_" . $filter_gnAD_gn211 . "\.txt";
#	if(not (-f $loc)){
#		push(@config_errors, "filter_gnomad_genome211 : $loc is not readable");
#	}else{
#		my $db_detail = $cfgs_detail{'filter_gnomad_genome211'};
#		$db_versions{'Filter'}{'gnomad_genome211'} = (split('\|', $db_detail))[1];
#		$annovar_filter_module{'gnomad_genome211'}{db} = $filter_gnAD_gn211;
#		$annovar_filter_module{'gnomad_genome211'}{db_dir} = $gnAD_dir;
#	}

	my $filter_cg2     = "";
	my $filter_cgWel   = "";
	my $filter_cg1000g = "";
	my $bed_cgInt = "";
	my $bed_illInt = "";

	if ( $run_is_mssng == 1 ) {
		$filter_cg2 =
		  ( exists $cfgs{filter_cg} )
		  ? $cfgs{filter_cg}
		  : push( @config_errors, "filter_cg" );
		my $db_detail = $cfgs_detail{'filter_cg'};
		$db_versions{'Filter'}{'CG'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'CG'}{db} = $filter_cg2;

		$filter_cgWel =
		  ( exists $cfgs{filter_cgWellderly} )
		  ? $cfgs{filter_cgWellderly}
		  : push( @config_errors, "filter_cgWellderly" );
		my $db_detail = $cfgs_detail{'filter_cgWellderly'};
		$db_versions{'Filter'}{'Welderly'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'Welderly'}{db} = $filter_cgWel;

		$filter_cg1000g =
		  ( exists $cfgs{filter_cg1KGf} )
		  ? $cfgs{filter_cg1KGf}
		  : push( @config_errors, "filter_cg1KGf" );
		my $db_detail = $cfgs_detail{'filter_cg1KGf'};
		$db_versions{'Filter'}{'cg1KB'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'cg1KB'}{db} = $filter_cg1000g;

		$bed_cgInt =
		  ( exists $cfgs{bed_cgInt} )
		  ? $cfgs{bed_cgInt}
		  : push( @config_errors, "bed_cgInt" );
		my $db_detail = $cfgs_detail{'bed_cgInt'};
		
		$bed_illInt =
		  ( exists $cfgs{bed_illInt} )
		  ? $cfgs{bed_illInt}
		  : push( @config_errors, "bed_illInt" );
		my $db_detail = $cfgs_detail{'bed_illInt'};		
		#$db_versions{'Filter'}{'cg1KB'} = ( split( '\|', $db_detail ) )[1];
	#	$annovar_filter_module{'cg1KB'}{db} = $filter_cg1000g;
		
	}

	my $bed_spidex = "";

	#if($run_is_mssng != 1){
	$bed_spidex =
	  ( exists $cfgs{spidex_bed} )
	  ? $cfgs{spidex_bed}
	  : push( @config_errors, "spidex_bed" );
	if ( not( -f $bed_spidex ) ) {
		push( @config_errors, "spidex_bed : $bed_spidex is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'spidex_bed'};
		$db_versions{'Splicing'}{'spidex'} = ( split( '\|', $db_detail ) )[1];
		$bedops_filter_module{'spidex'}{db} = $bed_spidex;
	}

	#}

	my $bed_cadd =
	  ( exists $cfgs{cadd_bed} )
	  ? $cfgs{cadd_bed}
	  : push( @config_errors, "cadd_bed" );
	if ( not( -f $bed_cadd ) ) {
		push( @config_errors, "cadd_bed : $bed_cadd is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'cadd_bed'};
		$db_versions{'Prediction'}{'cadd'} = ( split( '\|', $db_detail ) )[1];
		$bedops_filter_module{'cadd'}{db} = $bed_cadd;
	}

	my $region_phst =
	  ( exists $cfgs{region_phst} )
	  ? $cfgs{region_phst}
	  : push( @config_errors, "region_phst" );
	my $db_detail = $cfgs_detail{'region_phst'};
	$db_versions{'Conservation'}{'phastcon'} = ( split( '\|', $db_detail ) )[1];
	$annovar_region_module{'phastcon'}{dbtype} = $region_phst;

	my $region_segdup =
	  ( exists $cfgs{region_segdup} )
	  ? $cfgs{region_segdup}
	  : push( @config_errors, "region_segdup" );
	my $db_detail = $cfgs_detail{region_segdup};
	$db_versions{'Misc'}{'segdup'} = ( split( '\|', $db_detail ) )[1];
	$annovar_region_module{'segdup'}{dbtype}    = $region_segdup;
	$annovar_region_module{'segdup'}{db_prefix} = "genomicSuperDups";

#my $filter_phylop_ex = (exists $cfgs{filter_phylop_ex}) ? $cfgs{filter_phylop_ex} : push(@config_errors, "region_phylop_ex");

	my $phylop_100w_dir =
	  ( exists $cfgs{phylop_100w_dir} )
	  ? $cfgs{phylop_100w_dir}
	  : push( @config_errors, "phylop_100w_dir" );
	if ( not( -f $phylop_100w_dir ) ) {
		push( @config_errors, "phylop_100w  : $phylop_100w_dir  not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{phylop_100w_dir};
		$db_versions{'Conservation'}{'phylop_100way'} =
		  ( split( '\|', $db_detail ) )[1];

		#$bedops_region_module{'phylop_100way'}{db_dir} = $phylop_100w_dir;
	}

	my $phylop_pl_dir =
	  ( exists $cfgs{phylop_wg_dir} )
	  ? $cfgs{phylop_wg_dir}
	  : push( @config_errors, "phylop_wg_dir" );
	if ( not( -f $phylop_pl_dir ) ) {
		push( @config_errors, "phylop_pl_dir  :$phylop_pl_dir  not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{phylop_wg_dir};
		$db_versions{'Conservation'}{'phylop_placental'} =
		  ( split( '\|', $db_detail ) )[1];
	}

	#dbsnp region
	my $region_dbsnp_bed =
	  ( exists $cfgs{region_dbsnp_bed} )
	  ? $cfgs{region_dbsnp_bed}
	  : push( @config_errors, "region_dbsnp_bed" );
	if ( not( -f $region_dbsnp_bed ) ) {
		push( @config_errors,
			"dbsnp region_bed   : $region_dbsnp_bed  not readale" );
	}
	else {

		#$bedops_region_module{'dbsnp region'}{db} = $region_dbsnp_bed;
	}

	my $filter_dng = "NA";

	#dbscSnv , added Feb 08, 2016
	my $filter_dbscsnv =
	  ( exists $cfgs{filter_dbscsnv} )
	  ? $cfgs{filter_dbscsnv}
	  : push( @config_errors, "filter_dbscsnv" );
	my $loc = $annovar_ext_db . "/" . $build . "_" . $filter_dbscsnv . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_dbscsnv : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_dbscsnv'};
		$db_versions{'Splicing'}{'dbscsnv'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'dbscsnv'}{db} = $filter_dbscsnv;
	}

#spliceAIsnv , added Oct 09, 2019
#my $filter_spliceAIsnv = (exists $cfgs{filter_spliceAIsnv}) ?  $cfgs{filter_spliceAIsnv} :push(@config_errors, "filter_spliceAIsnv") ;
	my $bed_spliceAIsnv =
	  ( exists $cfgs{bed_spliceAIsnv} )
	  ? $cfgs{bed_spliceAIsnv}
	  : push( @config_errors, "bed_spliceAIsnv" );

	my $filter_cosmic =
	  ( exists $cfgs{filter_cosmic} )
	  ? $cfgs{filter_cosmic}
	  : push( @config_errors, "filter_cosmic" );
	my $loc = $annovar_ext_db . "/" . $build . "_" . $filter_cosmic . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_cosmic : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_cosmic'};
		$db_versions{'Misc'}{'cosmic'} = ( split( '\|', $db_detail ) )[1];
		$annovar_filter_module{'cosmic'}{db} = $filter_cosmic;
	}

	my $bed_pfam =
	  ( exists $cfgs{bed_pfam} )
	  ? $cfgs{bed_pfam}
	  : push( @config_errors, "bed_pfam" );
	my $loc = $annovar_ext_db . "/" . $bed_pfam;
	if ( not( -f $loc ) ) {
		push( @config_errors, "bed_pfam : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'bed_pfam'};
		$db_versions{'Misc'}{'pfam'} = ( split( '\|', $db_detail ) )[1];
		$annovar_region_module{'pfam'}{bed}    = $bed_pfam;
		$annovar_region_module{'pfam'}{dbtype} = 'bed';
	}

	#gerpelm
	if ( $build eq "hg19" ) {
		my $bed_gerpelm =
		  ( exists $cfgs{bed_gerp_elem} )
		  ? $cfgs{bed_gerp_elem}
		  : push( @config_errors, "bed_gerp_elem" );
		my $loc = $annovar_ext_db . "/" . $bed_gerpelm;
		if ( not( -f $loc ) ) {
			push( @config_errors, "bed_gerp_elem : $loc is not readable" );
		}
		else {
			my $db_detail = $cfgs_detail{'gerp_elem'};
			$db_versions{'Conservation'}{'gerp_elem'} =
			  ( split( '\|', $db_detail ) )[1];
			$annovar_region_module{'gerp_elem'}{bed}    = $bed_gerpelm;
			$annovar_region_module{'gerp_elem'}{dbtype} = 'bed';
		}
	}

#	my $fiter_gerpwgs =  (exists $cfgs{filter_gerp_wgs}) ? $cfgs{filter_gerp_wgs} : push(@config_errors, "filter_gerp_wgs");
#	my $loc = $annovar_ext_db . "/" . $build . "_" .  $fiter_gerpwgs . ".txt" ;
#	if(not (-f $loc)){
#		push(@config_errors, "filter_gerp_wgs : $loc is not readable");
#	}else{
#		my $db_detail = $cfgs_detail{'filter_gerp_wgs'};
#		$db_versions{'Conservation'}{'gerp_wgs'} = (split('\|', $db_detail))[1];
#		$annovar_filter_module{'gerp_wgs'}{db} =  $fiter_gerpwgs;
#	}

#	#gerpwgs
#	my $fiter_gerpwgs =  (exists $cfgs{filter_gerp_wgs}) ? $cfgs{filter_gerp_wgs} : push(@config_errors, "filter_gerp_wgs");
#	my $loc = $annovar_ext_db . "/" . $build . "_" .  $fiter_gerpwgs . ".txt" ;
#	if(not (-f $loc)){
#		push(@config_errors, "filter_gerp_wgs : $loc is not readable");
#	}else{
#		my $db_detail = $cfgs_detail{'filter_gerp_wgs'};
#		$db_versions{'Conservation'}{'gerp_wgs'} = (split('\|', $db_detail))[1];
#		my $cno = 1;
#		foreach my $chkey (keys %chinfo){
#			$cno = $chkey;
#			if(exists $_chrs{$chkey}){
#                my $cno_file0 = $chinfo{$chkey};
#                my ($cno_file , $cnw_file) = split("\t" , $cno_file0);
#                $cno =~ s/chr//;
#                print $fh_log "grepwgs $chkey\n";
#                my $this_gerpwgs_id = "gerpwgs:" . $cno;
#                $annovar_filter_module{$this_gerpwgs_id}{db} =  $fiter_gerpwgs;
#			}
#		}
#	}

	my $fiter_hgmd_pro = "";
	if ( $run_is_mssng == 0 && $run_no_hgmd == 0 ) {
		$fiter_hgmd_pro =
		  ( exists $cfgs{filter_hgmd_pro} )
		  ? $cfgs{filter_hgmd_pro}
		  : push( @config_errors, "filter_hgmd_pro" );
		my $loc =
		  $annovar_ext_db . "/" . $build . "_" . $fiter_hgmd_pro . ".txt";
		if ( not( -f $loc ) ) {
			push( @config_errors, "filter_hgmd_pro : $loc is not readable" );
		}
		else {
			my $db_detail = $cfgs_detail{'filter_hgmd_pro'};
			$db_versions{'Misc'}{'hgmd_pro'} = ( split( '\|', $db_detail ) )[1];
			$annovar_filter_module{'hgmd_pro'}{db} = $fiter_hgmd_pro;
		}
	}
	else {
		warn "** MSSNG / --no_hgmd, skipping HGMD annotations..\n";
	}
	my $annovar_gene_type =
	  ( exists $cfgs{annovar_gene_type} )
	  ? $cfgs{annovar_gene_type}
	  : push( @config_errors, "annovar_gene_type" );

	my $mpo_file =
	  ( exists $cfgs{MPO} ) ? $cfgs{MPO} : push( @config_errors, "MPO" );
	if ( not( -f $mpo_file ) ) {
		push( @config_errors, "MPO : $mpo_file not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{MPO};
		$db_versions{'Gene'}{'MPO'} = ( split( '\|', $db_detail ) )[1];
	}

	my $hpo_file =
	  ( exists $cfgs{HPO} ) ? $cfgs{HPO} : push( @config_errors, "HPO" );
	if ( not( -f $hpo_file ) ) {
		push( @config_errors, "HPO : $hpo_file not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{HPO};
		$db_versions{'Gene'}{'HPO'} = ( split( '\|', $db_detail ) )[1];
	}

	my $cgd_file =
	  ( exists $cfgs{CGD} ) ? $cfgs{CGD} : push( @config_errors, "CGD" );
	if ( not( -f $cgd_file ) ) {
		push( @config_errors, "CGD : $cgd_file not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{CGD};
		$db_versions{'Gene'}{'CGD'} = ( split( '\|', $db_detail ) )[1];
	}

	my $exmat_file =
	  ( exists $cfgs{ExAc_Matrics} )
	  ? $cfgs{ExAc_Matrics}
	  : push( @config_errors, "ExAc_Matrics" );
	if ( not( -f $exmat_file ) ) {
		push( @config_errors, "ExAc_Matrics : $exmat_file not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{ExAc_Matrics};
		$db_versions{'Gene'}{'ExAc_Matrics'} = ( split( '\|', $db_detail ) )[1];
	}

	my $morbidmap_file =
	  ( exists $cfgs{morbidmap} )
	  ? $cfgs{morbidmap}
	  : push( @config_errors, "morbidmap" );
	if ( not( -f $morbidmap_file ) ) {
		push( @config_errors, "morbidmap : $morbidmap_file not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{morbidmap};
		$db_versions{'Gene'}{'morbidmap'} = ( split( '\|', $db_detail ) )[1];
	}

	my $acmg_file =
	  ( exists $cfgs{ACMG} )
	  ? $cfgs{ACMG}
	  : push( @config_errors, "ACMG genes file" );
	if ( not( -f $acmg_file ) ) {
		push( @config_errors, "ACMG : $acmg_file not readale" );
	}
	else {
		my $db_detail = $cfgs_detail{ACMG};
		$db_versions{'Gene'}{'ACMG'} = ( split( '\|', $db_detail ) )[1];
	}

	my $db_update = $cfgs{database_update};
	my $nc1_db    = $cfgs{nc1};
	my $nc2_db    = $cfgs{nc2};
	my $nc3_db    = $cfgs{nc3};
	my $nc4_db    = $cfgs{nc4};
	my $nc5_db    = $cfgs{nc5};
	my $nc6_db    = $cfgs{nc6};
	my $nc7_db    = $cfgs{nc7};
	my $rep_db =
	  ( exists $cfgs{repeat} )
	  ? $cfgs{repeat}
	  : push( @config_errors, "repeat" );
	my $loc = $annovar_ext_db . "/" . $build . "_" . $rep_db . "\.txt";
	$annovar_region_module{'repeat'}{dbtype} = $rep_db;

	if ( not( -f $loc ) ) {
		push( @config_errors, "repeat db : $loc is not readable" );
	}

	#genome
	my $cg_genome = -1;
	$cg_genome = ( exists $cfgs{genome} ) ? $cfgs{genome} : -1;
	my $vcf_genome = $cg_genome;
	if ( defined $options{g} ) {
		$vcf_genome = $options{g};
		$cg_genome  = $options{g};
	}
	if ( not( -f $cg_genome ) ) {
		push( @config_errors, "genome :  $cg_genome is not readale" );
	}

	my $db_refFlat =
	  ( exists $cfgs{refFlat} )
	  ? $cfgs{refFlat}
	  : push( @config_errors, "refFlat" );
	if ( not( -f $db_refFlat ) ) {
		push( @config_errors, "refFlat : $db_refFlat not readale" );
	}

	my $db_refGene =
	  ( exists $cfgs{refGene} )
	  ? $cfgs{refGene}
	  : push( @config_errors, "refGene" );
	if ( not( -f $db_refGene ) ) {
		push( @config_errors, "refGene : $db_refGene not readale" );
	}

	my $db_ucGene =
	  ( exists $cfgs{ucscGene} )
	  ? $cfgs{ucscGene}
	  : push( @config_errors, "ucscGene" );
	if ( not( -f $db_ucGene ) ) {
		push( @config_errors, "ucscGene : $db_ucGene  not readale" );
	}

	my $db_geneInfo =
	  ( exists $cfgs{'entrez_map'} )
	  ? $cfgs{'entrez_map'}
	  : push( @config_errors, "entrez_map" );
	if ( not( -f $db_geneInfo ) ) {
		push( @config_errors, "gene_info : $db_geneInfo not readale" );
	}

	my $db_refLink =
	  ( exists $cfgs{refLink} )
	  ? $cfgs{refLink}
	  : push( @config_errors, "refLink" );
	if ( not( -f $db_refLink ) ) {
		push( @config_errors, "refLink : $db_refLink not readale" );
	}

	my $db_kgXref =
	  ( exists $cfgs{kgXref} )
	  ? $cfgs{kgXref}
	  : push( @config_errors, "kgXref" );
	if ( not( -f $db_kgXref ) ) {
		push( @config_errors, "kgXref : $db_kgXref not readale" );
	}

#	#hg38_ambiguous_sites=/hpf/largeprojects/tcagstor/users/thomas/Annotation/Human/hg38/mssng/v01052019/db/hg38_ambiguous_sites.txt
	my $db_hg39Ambg =
	  ( exists $cfgs{hg38_ambiguous_sites} )
	  ? $cfgs{hg38_ambiguous_sites}
	  : push( @config_errors, "hg38_ambiguous_sites" );
	if ( not( -f $db_hg39Ambg ) ) {
		push( @config_errors,
			"hg38_ambiguous_sites : $db_hg39Ambg not readale" );
	}

	my $refRlx_gene =
	  ( exists $cfgs{refgene_relaxed} )
	  ? $cfgs{refgene_relaxed}
	  : push( @config_errors, "refgene_relaxed gene type" );
	my $refSel_gene =
	  ( exists $cfgs{refgene_select} )
	  ? $cfgs{refgene_select}
	  : push( @config_errors, "refgene_select(MANE) gene type" );

	my $cleanup_script = $cfgs{'cleanup_script'};

	if ( ( scalar @config_errors ) != 0 ) {
		my $cfg_error = join( "\n", @config_errors );
		&usage( "Following db(s) are missing/have issues in " 
			  . $config . "\n "
			  . $cfg_error );
	}

	my $output_cfg_file =
	  $tool_home . "/scripts/output_" . $pipeline_rev . ".cfg";

	if ( defined $options{'oc'} ) {
		$output_cfg_file = $options{'oc'};
	}

	my $output_cfg_file_def =
	  $output_cfg_file;   # for future verification if user input different(TBA)
	print STDOUT "** output config = $output_cfg_file_def ** \n";

	if ( exists $cfgs{outConfig} ) {
		$output_cfg_file = $cfgs{outConfig};
	}
	if ( not( -f $output_cfg_file ) ) {
		&usage( "(System Error!)Output config file is not readable:  "
			  . $output_cfg_file );
	}

	#Update info:
	my $fh_updG = IO::File->new( "$annovar_gene_db/update.log", q{<} );
	my $gene_update = <$fh_updG>;

	my $fh_updE = IO::File->new( "$annovar_ext_db/update.log", q{<} );
	my $ext_update = <$fh_updE>;

	$db_versions{'Gene'}{'gene'}      = $gene_update;
	$db_versions{'Genome'}{'build'}   = $cfgs{build};
	$db_versions{'Gene'}{'gene_type'} = $cfgs{annovar_gene_type};

	my $run_base_dir       = $run_work_dir;
	my $run_input_basename = basename($run_input);
	my $tmp_directory      = $run_input_basename . "_TMP";
	system("cd $run_base_dir");
	system("mkdir -p $run_base_dir/$tmp_directory");
	my $log_file       = $log_dir . "/" . $input_basename . ".log";
	my $process_log    = $log_dir . "/" . $input_basename . "_process.log";
	my $db_version_log = $log_dir . "/" . $input_basename . "_db.versions.json";

	my $monitor_out = $log_dir . "/" . $input_basename . "_status.txt";
	my $monitor_out2 =
	  $log_dir . "/" . $input_basename . "_Annotation_workflow.json";
	my $monitor_out3 =
	  $log_dir . "/" . $input_basename . "_Annotation_workflow.txt";

	my $meta_file = $log_dir . "/" . $input_basename . "\.pipeline_meta.txt";
	my $fh_mta = IO::File->new( $meta_file, q{>} )
	  or die &usage("Error in creating $meta_file\n");
	my $fh_proc = IO::File->new( $process_log, q{>} )
	  or die &usage("Error in creating $process_log\n");
	print $fh_proc "Pipeline started at : ", localtime(), "\n";

	#**** version log , to be modified
	print_versions( \%db_versions, $db_version_log );

	print "base-dir=$run_base_dir\n";
	print "log-dir=$run_log_dir\n";
	print "pipeline_version = $0\n";
	print "Config file = $run_config\n";
	print "Input  = $run_input\n";

	my $fh_log = IO::File->new( $log_file, q{>} )
	  or die &usage("Error in creating $log_file\n");

	print $fh_log "pipeline_version = $0\n";
	print $fh_log "Config file = $run_config\n";

#print $fh_log "Pipeline_extra module version  = " ,  Parse::Annovar::VERSION , "\n\n";

	my %process_status  = ();
	my $pipe_start_time = localtime;
	$process_status{'pipeline'}{start_time}   = $pipe_start_time;
	$process_status{'pipeline'}{end_time}     = "NA";
	$process_status{'pipeline'}{exit_status}  = "NA";
	$process_status{'pipeline'}{work_dir}     = $run_work_dir;
	$process_status{'pipeline'}{log_dir}      = $run_log_dir;
	$process_status{'pipeline'}{post_process} = $run_type_ppr;
	$process_status{'pipeline'}{script}       = $0;
	$process_status{'pipeline'}{cov_file}     = $run_cov_file;
	$process_status{'pipeline'}{annovar_home} = $annovar_home;
	$process_status{'pipeline'}{build_ver}    = $build;
	$process_status{'pipeline'}{org_input}    = $run_orginal_input;
	$process_status{'pipeline'}{rev}          = $pipeline_rev;
	$process_status{'pipeline'}{impact}       = $run_calc_impact;
	$process_status{'pipeline'}{mssng}        = $run_is_mssng;
	$process_status{'pipeline'}{norm_vcf}     = $vcf2format;

	if ( defined $vcf_smp_file ) {
		$process_status{'pipeline'}{vcf_sample_file} = $vcf_smp_file;
	}

	#$process_status{'pipeline'}{hg38_ambiguous_sites} = $db_hg39Ambg;

	push( @job_names, "pipeline" );

	print $fh_log "\nContens of Config file: \n";
	foreach my $ck ( sort ( keys %cfgs ) ) {
		print $fh_log $ck, " = ", $cfgs_detail{$ck}, "\n";
	}

	chomp($gene_update);
	chomp($ext_update);
	print $fh_log "$gene_update\n";
	print $fh_log "$ext_update\n";
	$process_status{'pipeline'}{gene_update} = $gene_update;
	$process_status{'pipeline'}{ext_update}  = $ext_update;
	$process_status{'pipeline'}{ext_db}      = $annovar_ext_db;
	$process_status{'pipeline'}{gene_db}     = $annovar_gene_db;

	my $vcf_in     = $run_input;
	my $annovar_in = $run_input;

	#added June 8, 2017 skip random chromosomes
	my @_CHR = 1 .. 22;
	foreach ( 1 .. 22 ) {
		push( @_CHR, "chr" . $_ );
	}
	push( @_CHR, ( "X", "Y", "chrX", "chrY", "MT", "chrM" ) )
	  ;    # add more if you've db for special chromosomes

	my $tmp_dir = $run_base_dir . "/" . $tmp_directory . "/";
	$annovar_in =
	    $run_base_dir . "/"
	  . $tmp_directory . "/"
	  . $run_input_basename
	  . ".annovar.in.txt";
	my $dbsnp_r =
	    $run_base_dir . "/"
	  . $tmp_directory . "/"
	  . $run_input_basename
	  . ".annovar.sub.txt";
	my $dbsnp_w =
	    $run_base_dir . "/"
	  . $tmp_directory . "/"
	  . $run_input_basename
	  . ".annovar.ind.txt";
	my $nonc_w =
	    $run_base_dir . "/"
	  . $tmp_directory . "/"
	  . $run_input_basename
	  . ".annovar.ncw.txt";
	my $m_subset =
	    $run_base_dir . "/"
	  . $tmp_directory . "/"
	  . $run_input_basename
	  . ".subset.txt";
	my $input_bedops =
	    $run_base_dir . "/"
	  . $tmp_directory . "/"
	  . $run_input_basename
	  . ".bedops.bed";
	my $chr_info =
	    $run_base_dir . "/"
	  . $tmp_directory . "/"
	  . $run_input_basename
	  . ".chrInfo.txt";

	#need to modify above if appris effect is enabled
	if ( $appris_effect == 1 ) {
		print STDOUT ".. For APPRIS, need to modify $output_cfg_file\n";
		my $output_cfg_file_appr =
		    $run_base_dir . "/"
		  . $tmp_directory . "/"
		  . $run_input_basename
		  . "_out_config.cfg";
		open( OCF, $output_cfg_file ) or die "$! $output_cfg_file\n";
		open( ACF, ">$output_cfg_file_appr" )
		  or die "$! $output_cfg_file_appr\n";

		#effect_priority
		while ( my $cfg_line = <OCF> ) {
			chomp($cfg_line);
			print ACF $cfg_line, "\n";
			if ( $cfg_line eq "effect_priority" ) {
				print ACF "effect_appris\n";
			}
		}
		close OCF;
		close ACF;
		$output_cfg_file = $output_cfg_file_appr;
	}

	$process_status{'pipeline'}{tmp_dir}            = $tmp_dir;
	$process_status{'pipeline'}{tool_home}          = $tool_home;
	$process_status{'pipeline'}{orig_input}         = $run_input;
	$process_status{'pipeline'}{annovar_in}         = $annovar_in;
	$process_status{'pipeline'}{config_file}        = $run_config;
	$process_status{'pipeline'}{output_config}      = $output_cfg_file;
	$process_status{'pipeline'}{chr_info}           = $chr_info;
	$process_status{'pipeline'}{splicing_threshold} = $sp_threshold;
	$process_status{'pipeline'}{neargene}           = $neargene;
	$process_status{'pipeline'}{add_gene_opt}       = $add_gene_opt;
	$process_status{'pipeline'}{custom_gene}        = $custom_gene;

	$process_status{'Phenotype'}{morbidmap} = $morbidmap_file;
	$process_status{'Phenotype'}{HPO}       = $hpo_file;
	$process_status{'Phenotype'}{MPO}       = $mpo_file;
	$process_status{'Phenotype'}{CGD}       = $cgd_file;

	#	$process_status{'Phenotype'}{GI} = $gi_file ;
	#	$process_status{'Phenotype'}{HI} = $hi_file ;
	$process_status{'Phenotype'}{ExAc_Matrics} = $exmat_file;
	$process_status{'Phenotype'}{ACMG}         = $acmg_file;

	#$process_status{'clinvar_summary'}{file} = $clinvar_summary;

	#bzip2 files
	my $input_to_go   = $run_input;
	my $input_to_conv = $run_input;
	if ( $input =~ m/.+\.bz2$/ ) {
		$process_status{'pipeline'}{bzip} = 1;
		$input_to_go =~ s/\.bz2//;
		$input_to_conv = $run_base_dir . "/" . basename($input_to_go);
		print $fh_log "bzip2 conversion: \n";
		my $bz2cov_command = "bzip2 -c -d $run_input > $input_to_conv";
		print $fh_log "$bz2cov_command\n";
		print $fh_proc "**bz2cov  started\n";
		my $ex_st = system($bz2cov_command);
		$no_of_jobs++;
		$process_status{bz2cov}{exit_status} = $ex_st;

		if ( $ex_st == 0 ) {
			print $fh_proc "**bz2cov  is finished  with exit code: $?\n";
		}
		else {
			print $fh_proc "bz2cov is failed with exit code: $?\n";
			warn "bz2cov is failed with exit code: $?\n";
			usage("Critical error! bz2cov is failed");
		}

	}
	else {
		print $fh_log "$input_to_conv tsv file\n";
		$process_status{'pipeline'}{bzip} = 0;
	}
	$process_status{'pipeline'}{run_type}    = $run_in_file_type;
	$process_status{'pipeline'}{input_to_go} = $input_to_conv;

	#********* To be modified
	#job_status(\%process_status);

	if ( $run_type eq "v" || $run_type eq "u" ) {

		#vcf to annovar conversion
		print LOG "Convert to annovar format: \n";
		my $svcf = Vcfparse->new($vcf_in);
		my @split_list =
		  $svcf->split2_small( $run_base_dir . "/" . $tmp_directory, 350000 );
		my $cov2ann_outf =
		  $run_base_dir . "/" . $tmp_directory . "/cov2annovar.list";
		my $fh_cal = IO::File->new( $cov2ann_outf, q{>} )
		  or die "$! $cov2ann_outf\n";
		my @cov2ann_cmds     = ();
		my %cov2ann_pr_names = ();
		my $cov2ann_jobid    = 1;

		foreach my $each_in (@split_list) {
			my $this_annovar_in = $each_in . "_annovar.in";
			print $fh_cal $each_in, "\t", $this_annovar_in, "\n";
			my $c2a_command =
"perl -X $annovar_home\/convert2annovar.pl -format vcf4old  -include -outfile $this_annovar_in $each_in";
			print $fh_log "Convert2annovar:\n";
			print $fh_log "$c2a_command\n";
			if ( $somatic == 1 ) {
				$c2a_command =
"perl -X $annovar_home\/convert2annovar.pl -format vcf4old  -include -outfile $this_annovar_in $each_in";
				print $fh_log "$c2a_command\n";
			}
			push( @cov2ann_cmds, $c2a_command );
			$cov2ann_pr_names{$cov2ann_jobid} =
			  "conv2annovar-" . $cov2ann_jobid;
			push( @job_names, "conv2annovar-" . $cov2ann_jobid );
			$process_status{ "conv2annovar-" . $cov2ann_jobid }{command} =
			  $c2a_command;
			$cov2ann_jobid++;
		}

		#run parallel
		my $ang2 =
		  AnnotationEngine->new( \%process_status, \@job_names, $monitor_out );
		$ang2->fork_manager($cores);

		#merge
		$annovar_in = $svcf->merge2_one( $run_base_dir . "/" . $tmp_directory,
			$cov2ann_outf );
		warn "*** annovar-in = $annovar_in\n";

		print $fh_log "Setting Additional input gen: \n";
		Parse::Annovar::generate_sub_wind_inputs( $annovar_in, $dbsnp_r,
			$dbsnp_w, $chr_info, $tmp_dir, $run_type_original );

	}
	else {    #($run_type eq "v" || $run_type eq "u")
		$annovar_in = $run_input;

	}
	$process_status{'pipeline'}{annovar_in} = $annovar_in;

	print $fh_log "Setting Additional input gen: \n";
	my $sw_count =
	  Parse::Annovar::generate_sub_wind_inputs( $annovar_in, $dbsnp_r, $dbsnp_w,
		$chr_info, $tmp_dir, $run_type_original );

	$process_status{'extra'}{exit_status} = "0";
	$process_status{'extra'}{dbsnp_r}     = $dbsnp_r;
	$process_status{'extra'}{dbsnp_w}     = $dbsnp_r;
	$process_status{'extra'}{command} =
"Parse::Annovar::generate_sub_wind_inputs\($annovar_in, $dbsnp_r, $dbsnp_w, $chr_info ,$tmp_dir\)";
	print $fh_log
"Parse::Annovar::generate_sub_wind_inputs\($annovar_in, $dbsnp_r, $dbsnp_w, $chr_info ,$tmp_dir\)\n";
	$process_status{'extra'}{count}          = $sw_count->{'total'};
	$process_status{'pipeline'}{input_count} = $sw_count->{'total'};

	print SUM "\n>>Genomic\n";
	foreach ( keys %{$sw_count} ) {
		if ( exists $sw_count->{$_} ) {
			print SUM $_, " = ", $sw_count->{$_}, "\n";
		}
	}

	push( @job_names, "extra" );

#$db->make_gene_db("/hpf/largeprojects/tcagstor/users/thomas/Annotation/Human/2020/dev/rev27.2/db/hg38/hg38_refGene.txt" , "/hpf/largeprojects/tcagstor/projects/pipeline_eval/broad-references/hg38/v0/Homo_sapiens_assembly38.fasta", "/hpf/largeprojects/tcagstor/users/thomas/Annotation/Human/2020/data/package/archives/APPRIS/20191205/test/hg38_refGeneApp", "P1,P2", "/hpf/largeprojects/tcagstor/users/thomas/tools/annovar/April_2018/");
	if ( $run_appris_effect == 1 ) {

		my $run_appris_genome =
		  ( exists $cfgs{refgene_genome} )
		  ? $cfgs{refgene_genome}
		  : usage("Error finding \'refgene_genome\' from config file! ");
		print $fh_log "Preparing db for appris-based effect \n";
		print $fh_log "Appris flags : $run_appris_flags \n";
		my $ap_db = Appris->new($run_appris_db);
		my $ap_db_out =
		    $run_base_dir . "/"
		  . $tmp_directory . "/"
		  . $build
		  . "_refGeneAppris";
		$ap_db->make_gene_db(
			$db_refGene,       $run_appris_genome, $ap_db_out,
			$run_appris_flags, $annovar_home
		);
		$process_status{'appris'}{exit_status} = "0";
		$process_status{'appris'}{input_db}    = $db_refGene;
		$process_status{'appris'}{out_db}      = "refGeneAppris";
		$process_status{'appris'}{flags}       = $run_appris_flags;
		push( @job_names, "appris" );
	}

	if ( $run_cus_gene == 1 ) {
		my $run_appris_genome =
		  ( exists $cfgs{refgene_genome} )
		  ? $cfgs{refgene_genome}
		  : usage("Error finding \'refgene_genome\' from config file! ");

		#$arguments{'custom-genome'}
		if ( exists $run_arg->{'custom-genome'} ) {
			$run_appris_genome = $run_arg->{'custom-genome'};
		}
		print $fh_log "Preparing db for custom-gene def\n";
		my $ap_db = Appris->new();
		my $ap_db_out =
		  $run_base_dir . "/" . $tmp_directory . "/" . $build . "_cusGene";
		$ap_db->make_db_from_custom_def( $run_cus_genedef, $run_appris_genome,
			$ap_db_out, $annovar_home );
		$process_status{'cus-gene'}{exit_status} = "0";
		$process_status{'cus-gene'}{input_db}    = $run_cus_genedef;
		$process_status{'cus-gene'}{out_db}      = "cusGene";
		push( @job_names, "cus-gene" );
	}
 
	my @bedops_sort_cmds     = ();
	my %bedops_sort_pr_names = ();
	my $bedops_sort_jobid    = 1;
	print STDOUT "Make bedops inputs..\n";

	my $annovar_in_bed =
	    $run_base_dir
	  . "/$tmp_directory/"
	  . $input_basename
	  . "_annovar_in_sorted.bed";
	my $annovar_in_bed_err =
	    $run_base_dir
	  . "/$tmp_directory/"
	  . $input_basename
	  . "_annovar_in_sortbed.err";
	if ( -not( -r $dbsnp_r ) ) {
		die "Critical! Bed sort error: File $dbsnp_r is not readable!..\n";
	}
	my $annovar_in_sort_command =
	    "cat " 
	  . $dbsnp_r
	  . '| awk -F\'\t\' \'{print $1"\t"($2-1)"\t"$3"\t"$4"\t"$5}\''
	  . "\| sort-bed --max-mem 2G - > $annovar_in_bed 2>$annovar_in_bed_err";
	print $fh_log "$annovar_in_sort_command\n";
	push( @bedops_sort_cmds, $annovar_in_sort_command );
	$bedops_sort_pr_names{$bedops_sort_jobid} = "bedsort-" . $bedops_sort_jobid;
	push( @job_names, 'bedops-sort' );
	$process_status{'bedops-sort'}{command} = $annovar_in_sort_command;
	my $ex_st = system($annovar_in_sort_command);
	$process_status{'bedops-sort'}{exit_status} = $ex_st;
	$process_status{'bedops-sort'}{output}      = $annovar_in_bed;

	if ( $ex_st == 0 ) {
		print $fh_proc "**bedops-sort is finished  with exit code: $?\n";
	}
	else {
		print $fh_proc "bedops-sort is failed with exit code: $?\n";
		warn "bedops-sort is failed with exit code: $?\n";
		usage("Critical error! bedops-sort is failed");
	}
	
	if($run_is_mssng == 1){
		##ann_chr
		print STDOUT "Make bedops inputs FOR MSSNG..\n";
		my $mssng_bed =    $run_base_dir  . "/$tmp_directory/"  . $input_basename 	  . "_org.bed";
		my $mssng_bed_err =  $run_base_dir  . "/$tmp_directory/"  . $input_basename  . "_org_sortbed.err";
		if ( -not( -r $annovar_in ) ) {
			die "Critical! Bed sort error: File $annovar_in is not readable!..\n";
		}
		
		my $mssng_sort_cmd = qq( grep -v '#ann_chr' $annovar_in | cut -f 8 | awk -F'-' '{print \$1"\\t"\$2"\\t"\$3"\\t"\$4"\\t"\$5}' |sort-bed --max-mem 2G -  > $mssng_bed 2>$mssng_bed_err );  
	  	print $fh_log "$mssng_sort_cmd\n";
	  	push( @job_names, 'mssng-bedsort' );
	  	$process_status{'mssng-bedsort'}{command} = $mssng_sort_cmd;
	  	my $ex_st = system($mssng_sort_cmd);

		$process_status{'mssng-bedsort'}{exit_status} = $ex_st;
		$process_status{'mssng-bedsort'}{output}      = $mssng_bed;

		if ( $ex_st == 0 ) {
			print $fh_proc "**mssng-bedsort is finished  with exit code: $?\n";
		}
		else {
			print $fh_proc "mssng-bedsort is failed with exit code: $?\n";
			warn "mssng-bedsort is failed with exit code: $?\n";
			usage("Critical error! mssng-bedsort is failed");
		}
	  	
	}

	if ( ( $type_ppr == 3.7 || $type_ppr == 3 ) && defined $options{t} ) {
		print STDOUT "Sorting target bed..\n";
		my $base_target = basename($ex_target_bed);
		my $target_bed_sorted =
		    $run_base_dir
		  . "/$tmp_directory/"
		  . $input_basename
		  . "_extarget_sorted.bed";
		my $target_bed_sort_cmd =
		    "cat $ex_target_bed | "
		  . q(awk '{print $1"\t"($2)"\t"$3"\t"$1":"$2":"$3}')
		  . " \| sort-bed - > $target_bed_sorted ";
		warn "$target_bed_sort_cmd\n";
		my $ex_stat = system($target_bed_sort_cmd);
		if ( $ex_stat != 0 ) {
			die "$target_bed_sort_cmd :  \n Error running bedop sorting ...;";
		}
		$process_status{'exome-target'}{bed}        = $ex_target_bed;
		$process_status{'exome-target'}{command}    = $target_bed_sort_cmd;
		$process_status{'exome-target'}{bed_sorted} = $target_bed_sorted;

		#closest module
		$bedops_closest_module{'target-dist'}{db} = $target_bed_sorted;

	}

	print STDOUT
"##Setting gene info file using $db_geneInfo , $db_refLink and $db_kgXref: \n";
	my $gfo_out =
	    $run_base_dir
	  . "/$tmp_directory" . "/"
	  . $input_basename
	  . ".geneInfo.txt";
	my $gfo_o =
	  $run_base_dir . "/$tmp_directory" . "/" . $input_basename . ".stats.out";
	my $gfo_e =
	  $run_base_dir . "/$tmp_directory" . "/" . $input_basename . ".stats.err";
	my $gfo_command =
"perl $tool_home\/scripts\/process_reflink_v4.pl $db_refLink $db_geneInfo  $db_kgXref $db_refGene $db_ucGene > $gfo_out 2> $gfo_e";
	print $fh_log "$gfo_command\n";

	#push(@cmds, $gfo_command);
	#	$pr_names{$proc++} = "gene_info";
	push( @job_names, "gene_info" );
	$process_status{'gene_info'}{refLink}  = $db_refLink;
	$process_status{'gene_info'}{geneInfo} = $db_geneInfo;
	$process_status{'gene_info'}{kgXref}   = $db_kgXref;
	$process_status{'gene_info'}{refGene}  = $db_refGene;
	$process_status{'gene_info'}{ucGene}   = $db_ucGene;
	$process_status{'gene_info'}{output}   = $gfo_out;
	$process_status{'gene_info'}{refFlat}  = $db_refFlat;
	$process_status{'gene_info'}{command}  = $gfo_command;
	$process_status{'gene_info'}{watch}    = 1;

	#vcf processing , added Aug 1,2019
	if ( $run_type_original eq "u" ) {
		my $vcfp_formatted_vcf =
		    $run_base_dir
		  . "/$tmp_directory" . "/"
		  . $input_basename
		  . "_extFull.tsv";
		my $vcfp_o =
		    $run_base_dir
		  . "/$tmp_directory" . "/"
		  . $input_basename
		  . ".vcfp.out";
		my $vcfp_e =
		    $run_base_dir
		  . "/$tmp_directory" . "/"
		  . $input_basename
		  . ".vcfp.err";
		my $vcfp_sum = $run_base_dir . "/$tmp_directory" . "/vcfp.stats";

		my $vcfp_command =
"perl $tool_home\/scripts\/vcf2tab_wrapper_v4.pl $vcf2format $vcfp_formatted_vcf $annovar_home $vcfp_sum $run_dng_meta > $vcfp_o 2>$vcfp_e";
		print $fh_log "vcf_pp command:  $vcfp_command\n";
		push( @job_names, "vcf_pp" );
		$process_status{'vcf_pp'}{output}        = $vcfp_formatted_vcf;
		$process_status{'vcf_pp'}{error_file}    = $vcfp_e;
		$process_status{'vcf_pp'}{command}       = $vcfp_command;
		$process_status{'vcf_pp'}{stat_file}     = $vcfp_sum;
		$process_status{'pipeline'}{input_to_go} = $vcfp_formatted_vcf;
		$process_status{'pipeline'}{annovar_in}  = $vcfp_formatted_vcf;
	}

	#parallel modules
	my @cmds     = ();
	my %pr_names = ();
	my $proc     = 1;

	my @all_module = ();

#my $this_annotation = Annovar->new($annovar_gene_db , $annovar_ext_db , "annovar_home" , "hg38" );

	my %chinfo = ();
	my $fh_cho = IO::File->new( $chr_info, q{<} ) or die "$! $chr_info\n";
	while ( my $cline = <$fh_cho> ) {
		chomp($cline);
		my ( $ckey, $cfile1, $cfile2 ) = ( split( "\t", $cline ) );
		$chinfo{ ( split( "\t", $cline ) )[0] } = ( split( "\t", $cline ) )[1];
		$chinfo{$ckey} = $cfile1 . "\t" . $cfile2;
	}

	my %_chrs = ();
	$_chrs{$_}++ for (@_CHR);

	print STDOUT " CHRS\n";
	print STDOUT Dumper \%_chrs, "\n";

	#gerpwgs
	my $fiter_gerpwgs =
	  ( exists $cfgs{filter_gerp_wgs} )
	  ? $cfgs{filter_gerp_wgs}
	  : push( @config_errors, "filter_gerp_wgs" );
	my $loc = $annovar_ext_db . "/" . $build . "_" . $fiter_gerpwgs . ".txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_gerp_wgs : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_gerp_wgs'};
		$db_versions{'Conservation'}{'gerp_wgs'} =
		  ( split( '\|', $db_detail ) )[1];
		my $cno = 1;
		foreach my $chkey ( keys %chinfo ) {
			$cno = $chkey;
			if ( exists $_chrs{$chkey} ) {
				my $cno_file0 = $chinfo{$chkey};
				my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
				$cno =~ s/chr//;
				print $fh_log "grepwgs $chkey\n";
				my $this_gerpwgs_id = "gerpwgs:" . $cno;
				$annovar_filter_module{$this_gerpwgs_id}{db} = $fiter_gerpwgs;
				$annovar_filter_module{$this_gerpwgs_id}{'annovar-in'} =
				  $cno_file;
			}
		}
	}

	#dbnsfp split , added sept 17, 2019
	my $filter_dbsnfp =
	  ( exists $cfgs{filter_dbnsfp} )
	  ? $cfgs{filter_dbnsfp}
	  : push( @config_errors, "filter_dbnsfp" );
	my $loc = $annovar_ext_db . "/" . $build . "_" . $filter_dbsnfp . "\.txt";
	if ( not( -f $loc ) ) {
		push( @config_errors, "filter_dbnsfp : $loc is not readable" );
	}
	else {
		my $db_detail = $cfgs_detail{'filter_dbnsfp'};
		$db_versions{'Prediction'}{'dbnsfp'} = ( split( '\|', $db_detail ) )[1];

		#		$annovar_filter_module{'dbnsfp'}{db} =  $filter_dbsnfp;
		my $cno = 1;
		foreach my $chkey ( keys %chinfo ) {
			$cno = $chkey;
			if ( exists $_chrs{$chkey} ) {
				my $cno_file0 = $chinfo{$chkey};
				my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
				$cno =~ s/chr//;
				print $fh_log "dbnsfp $chkey\n";
				my $this_dbnsfp_id = "dbnsfp:" . $cno;
				$annovar_filter_module{$this_dbnsfp_id}{db} = $filter_dbsnfp;
				$annovar_filter_module{$this_dbnsfp_id}{'annovar-in'} =
				  $cno_file;
			}
		}

	}

	#gnomAD genome211 , added Mar20,2020
	#hg38_nomad.genomes.r211ext_chr8.txt

	#my $db_detail = $cfgs_detail{'filter_gnomad_genome'};
	$db_versions{'Filter'}{'gnomad_genomeV211'} =
	  "v211, hg38, compiled from vcf";
	foreach my $chkey ( keys %chinfo ) {
		if($chkey =~ m/chrM/ || $chkey =~ m/MT/){
			next;
		}
		my $cno = $chkey;
		$cno =~ s/chr//;
		if ( exists $_chrs{$chkey} ) {
			my $filter_gnAD_gn = "gnomad.genomes.r211ext_chr" . $cno ;
			my $loc =
			  $gnAD_dir . "/" . $build . "_" . $filter_gnAD_gn . "\.txt";
			if ( not( -f $loc ) ) {
				push( @config_errors,
					"filter_gnomad211_genome : $loc is not readable" );
			}
			my $cno_file0 = $chinfo{$chkey};
			my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
			$cno =~ s/chr//;
			print $fh_log "gnomad_genome211 $chkey\n";
			my $this_gnAdg_id = "gnomad_genomeV211:" . $cno;
			$annovar_filter_module{$this_gnAdg_id}{db} = $filter_gnAD_gn;
			$annovar_filter_module{$this_gnAdg_id}{'annovar-in'} = $cno_file;
			$annovar_filter_module{$this_gnAdg_id}{db_dir} = $gnAD_dir;
		}

	}


	#gnomAD genome30 , added Mar20,2020
    # hg38_nomad.genomes.r30ext_chr19.txt
	#my $db_detail = $cfgs_detail{'filter_gnomad_genome'};
	$db_versions{'Filter'}{'gnomad_genomeV30'} =
	  "v30, hg38, compiled from vcf";
	foreach my $chkey ( keys %chinfo ) {
		if($chkey =~ m/chrM/ || $chkey =~ m/MT/){
			next;
		}

		my $cno = $chkey;
		$cno =~ s/chr//;
		if ( exists $_chrs{$chkey} ) {
			my $filter_gnAD_gn = "gnomad.genomes.r30ext_chr" . $cno;
			my $loc =
			  $gnAD_dir . "/" . $build . "_" . $filter_gnAD_gn . "\.txt";
			if ( not( -f $loc ) ) {
				push( @config_errors,
					"filter_gnomad30_genome : $loc is not readable" );
			}
			my $cno_file0 = $chinfo{$chkey};
			my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
			$cno =~ s/chr//;
			print $fh_log "gnomad_genome30 $chkey\n";
			my $this_gnAdg_id = "gnomad_genomeV30:" . $cno;
			$annovar_filter_module{$this_gnAdg_id}{db} = $filter_gnAD_gn;
			$annovar_filter_module{$this_gnAdg_id}{'annovar-in'} = $cno_file;
			$annovar_filter_module{$this_gnAdg_id}{db_dir} = $gnAD_dir;
		}

	}


	#}
	#gnomAD genome vcf , added mar 02, 2020
	my %vcf_module = ();
#	my $vcf_gnAD_gn =
#	  ( exists $cfgs{vcf_gnomad3_genome} )
#	  ? $cfgs{vcf_gnomad3_genome}
#	  : push( @config_errors, "vcf_gnomad3_genome" );
#	if ( not( -f $vcf_gnAD_gn ) ) {
#		usage("filter_gnomad_genome(vcf) : $vcf_gnAD_gn is not readable");
#	}
#	else {
#		my $db_detail = $cfgs_detail{'vcf_gnomad_genome'};
#		$db_versions{'Filter'}{'gnomad_genome'} =
#		  ( split( '\|', $db_detail ) )[1];
#		foreach my $chkey ( keys %chinfo ) {
#			my $cno = $chkey;
#			if ( exists $_chrs{$chkey} ) {
#				my $cno_file0 = $chinfo{$chkey};
#				my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
#				$cno =~ s/chr//;
#
#				print $fh_log "gnomad_genome(vcf) $chkey\n";
#				my $this_gnAdg_id = "gnomadGnV3:" . $cno;
#				$vcf_module{$this_gnAdg_id}{db}     = $vcf_gnAD_gn;
#				$vcf_module{$this_gnAdg_id}{vcf_in} = $dbsnp_r;
#				$vcf_module{$this_gnAdg_id}{chrom}  = $cno_file;
#				$vcf_module{$this_gnAdg_id}{script} =
#				  $tool_home . "\/scripts\/tabix_search_v4.pl";
#				$vcf_module{$this_gnAdg_id}{info_tags} =
#"AC,AC_female,AC_male,AF,AF_afr,AF_nfe,AF_ami,AF_amr,AF_asj,AF_eas,AF_female,AF_fin,AF_male,AF_oth,AF_raw,AF_sas,AN,AN_female,AN_male,faf95_adj,faf95_afr,faf95_amr,faf95_eas,faf95_nfe,faf95_sas,nhomalt,nhomalt_female,nhomalt_male";
#				$vcf_module{$this_gnAdg_id}{type}      = 2;
#				$vcf_module{$this_gnAdg_id}{watch}     = 1;
#				$process_status{$this_gnAdg_id}{watch} = 1;
#			}
#		}
#
#	}
#
#	#gnomAD 211
#	my $vcf_gnAD211_gn =
#	  ( exists $cfgs{vcf_gnomad211_genome} )
#	  ? $cfgs{vcf_gnomad211_genome}
#	  : push( @config_errors, "vcf_gnomad211_genome" );
#	if ( not( -f $vcf_gnAD211_gn ) ) {
#		usage("filter_gnomad_genome211(vcf) : $vcf_gnAD211_gn is not readable");
#	}
#	else {
#		my $db_detail = $cfgs_detail{'vcf_gnomad211_genome'};
#		$db_versions{'Filter'}{'gnomad_genome211'} =
#		  ( split( '\|', $db_detail ) )[1];
#		foreach my $chkey ( keys %chinfo ) {
#			my $cno = $chkey;
#			if ( exists $_chrs{$chkey} ) {
#				my $cno_file0 = $chinfo{$chkey};
#				my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
#				$cno =~ s/chr//;
#
#				print $fh_log "gnomad_genome211(vcf) $chkey\n";
#				my $this_gnAdg_id = "gnomadGnV211:" . $cno;
#				$vcf_module{$this_gnAdg_id}{db}     = $vcf_gnAD211_gn;
#				$vcf_module{$this_gnAdg_id}{vcf_in} = $dbsnp_r;
#				$vcf_module{$this_gnAdg_id}{chrom}  = $cno_file;
#				$vcf_module{$this_gnAdg_id}{script} =
#				  $tool_home . "\/scripts\/tabix_search_v4.pl";
#				$vcf_module{$this_gnAdg_id}{info_tags} =
#"AC,AC_female,AC_male,AF,AF_afr,AF_nfe,AF_amr,AF_asj,AF_eas,AF_female,AF_fin,AF_male,AF_oth,AF_raw,AF_sas,AN,AN_female,AN_male,faf95_afr,faf95_amr,faf95_eas,faf95_nfe,faf95_sas,nhomalt,nhomalt_female,nhomalt_male,controls_popmax";
#				$vcf_module{$this_gnAdg_id}{type}      = 2;
#				$vcf_module{$this_gnAdg_id}{watch}     = 1;
#				$process_status{$this_gnAdg_id}{watch} = 1;
#			}
#		}
#
#	}
#
#	#gnomAD 211 exome
#	my $vcf_gnAD211_ex =
#	  ( exists $cfgs{vcf_gnomad211_exome} )
#	  ? $cfgs{vcf_gnomad211_exome}
#	  : push( @config_errors, "vcf_gnomad211_exome" );
#	if ( not( -f $vcf_gnAD211_ex ) ) {
#		usage("filter_gnomad_exome211(vcf) : $vcf_gnAD211_ex is not readable");
#	}
#	else {
#		warn "****dbsnp_r = $dbsnp_r\n";
#		my $db_detail = $cfgs_detail{'vcf_gnomad211_exome'};
#		$db_versions{'Filter'}{'vcf_gnomad211_exome'} =
#		  ( split( '\|', $db_detail ) )[1];
#		print $fh_log "gnomad_exome211(vcf)\n";
#		my $this_gnAdg_id = "gnomadExV211";
#		$vcf_module{$this_gnAdg_id}{db}     = $vcf_gnAD211_ex;
#		$vcf_module{$this_gnAdg_id}{vcf_in} = $dbsnp_r;
#		$vcf_module{$this_gnAdg_id}{chrom}  = $dbsnp_r;
#		$vcf_module{$this_gnAdg_id}{script} =
#		  $tool_home . "\/scripts\/tabix_search_v4.pl";
#		$vcf_module{$this_gnAdg_id}{info_tags} =
#"AC,AC_female,AC_male,AF,AF_afr,AF_nfe,AF_amr,AF_asj,AF_eas,AF_female,AF_fin,AF_male,AF_oth,AF_raw,AF_sas,AN,AN_female,AN_male,faf95_afr,faf95_amr,faf95_eas,faf95_nfe,faf95_sas,nhomalt,nhomalt_female,nhomalt_male,controls_popmax";
#		$vcf_module{$this_gnAdg_id}{type}      = 2;
#		$vcf_module{$this_gnAdg_id}{watch}     = 1;
#		$process_status{$this_gnAdg_id}{watch} = 1;
#
#	}

#	my $loc = $annovar_ext_db .  "/" . $build . "_" . $filter_spliceAIsnv . "\.txt";
#	if(not (-f $loc)){
#		push(@config_errors, "filter_spliceAIsnv : $loc is not readable");
#	}else{
#		my $db_detail = $cfgs_detail{'filter_spliceAIsnv'};
#		$db_versions{'Splicing'}{'spliceAIsnv'} = (split('\|', $db_detail))[1];
#		$annovar_filter_module{'spliceAIsnv'}{db} =  $filter_spliceAIsnv;
#	}

	#$bedops_filter_module{'cadd'}{db} = $bed_cadd;
	#spliceAIsnv , added Oct 09, 2019
	my $bed_spliceAIsnv =
	  ( exists $cfgs{bed_spliceAIsnv} )
	  ? $cfgs{bed_spliceAIsnv}
	  : push( @config_errors, "bed_spliceAIsnv" );

#my $loc = $annovar_ext_db .  "/" . $build . "_" . $filter_spliceAIsnv . "\.txt";
	if ( not( -f $bed_spliceAIsnv ) ) {
		usage("bed_spliceAIsnv : $bed_spliceAIsnv is not readable");
	}
	else {
		my $db_detail = $cfgs_detail{'bed_spliceAIsnv'};
		$db_versions{'Splicing'}{'spliceAIsnv'} =
		  ( split( '\|', $db_detail ) )[1];
		$bedops_filter_module{'spliceAIsnv'}{db}    = $bed_spliceAIsnv;
		$bedops_filter_module{'spliceAIsnv'}{delim} = qq(">>");

#		my $cno = 1;
#		foreach my $chkey (keys %chinfo){
#			$cno = $chkey;
#			if(exists $_chrs{$chkey}){
#                my $cno_file0 = $chinfo{$chkey};
#                my ($cno_file , $cnw_file) = split("\t" , $cno_file0);
#                $cno =~ s/chr//;
#                print $fh_log "spliceAIsnv $chkey\n";
#                my $this_splAI_id = "spliceAIsnv:" . $cno;
#                $annovar_filter_module{$this_splAI_id}{db} =  $filter_spliceAIsnv;
#                $annovar_filter_module{$this_splAI_id}{'annovar-in'} =  $cno_file;
#                #$annovar_filter_module{$this_gnAdg_id}{db_dir} = $gnAD_dir;
#			}
#		}
	}

#	if(scalar(@config_errors) > 0){
#		usage("Following dbs are missing in config file: " , join("\n" , @config_errors) ) , "\n";
#	}

	my $ang2 =
	  AnnotationEngine->new( \%process_status, \@job_names, $monitor_out );

	my $this_vcf_module = $ang2->create_vcfAnno_pipeline( \%vcf_module );

	my $this_filter_module =
	  $ang2->create_filter_pipeline( \%annovar_filter_module );

	my $this_region_module =
	  $ang2->create_region_pipeline( \%annovar_region_module );

	my $this_bedopsf_module =
	  $ang2->create_bedops_filter_pipeline( \%bedops_filter_module );

	my $this_bedopcl_module =
	  $ang2->create_bedops_closest_pipeline( \%bedops_closest_module );

	my %annovar_gene_module = ();
	$annovar_gene_module{'Gene'}{gene_type}        = "refGene";
	$annovar_gene_module{'UCSC-Gene'}{gene_type}   = "knownGene";
	$annovar_gene_module{'Gene-Rlx'}{gene_type}    = $refRlx_gene;
	$annovar_gene_module{'Gene-Select'}{gene_type} = $refSel_gene;
	$annovar_gene_module{'Gene'}{watch}            = 1;
	$annovar_gene_module{'Gene-Rlx'}{watch}        = 1;
	$annovar_gene_module{'Gene-Select'}{watch}     = 1;
	$process_status{'Gene-Rlx'}{watch}             = 1;
	$process_status{'Gene-Select'}{watch}          = 1;
	$process_status{'Gene'}{watch}                 = 1;

	if ( $run_appris_effect == 1 ) {
		$annovar_gene_module{'Gene-Appris'}{gene_type} = "refGeneAppris";
		$annovar_gene_module{'Gene-Appris'}{db_dir} =
		  $run_base_dir . "/" . $tmp_directory . "/";
		$annovar_gene_module{'Gene-Appris'}{watch} = 1;
		$process_status{'Gene-Appris'}{watch}      = 1;
	}

	if ( $run_cus_gene == 1 ) {
		$annovar_gene_module{'Gene'}{gene_type}      = "cusGene";
		$annovar_gene_module{'UCSC-Gene'}{gene_type} = "cusGene";
		$annovar_gene_module{'Gene-Rlx'}{gene_type}  = "cusGene";
		$annovar_gene_module{'Gene'}{db_dir} =
		  $run_base_dir . "/" . $tmp_directory . "/";
		$annovar_gene_module{'UCSC-Gene'}{db_dir} =
		  $run_base_dir . "/" . $tmp_directory . "/";
		$annovar_gene_module{'Gene-Rlx'}{db_dir} =
		  $run_base_dir . "/" . $tmp_directory . "/";
	}

	#$annovar_gene_module{'Gene'}{splicing_threshold} = $sp_threshold;
	#$annovar_gene_module{'UCSC-Gene'}{splicing_threshold} = $sp_threshold;
	#$annovar_gene_module{'Gene-Rlx'}{splicing_threshold} = $sp_threshold;

	my $this_gene_module =
	  $ang2->create_geneAnno_pipeline( \%annovar_gene_module );

	my $cno                  = 1;
	my %bedops_phylop_module = ();
	foreach my $chkey ( keys %chinfo ) {
		$cno = $chkey;
		if ( exists $_chrs{$chkey} ) {
			my $cno_file0 = $chinfo{$chkey};
			my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
			$cno =~ s/chr//;
			print $fh_log "phylop wg (100w) for $chkey\n";
			my $phy_name = "phylop100:" . $cno;
			$bedops_phylop_module{$phy_name}{db}       = $phylop_100w_dir;
			$bedops_phylop_module{$phy_name}{chrkey}   = $chkey;
			$bedops_phylop_module{$phy_name}{echo_map} = " --echo-map-score";
			$bedops_phylop_module{$phy_name}{post_process} = "phylop";

		}
	}

	my $cno                   = 1;
	my %bedops_phylop2_module = ();
	foreach my $chkey ( keys %chinfo ) {
		$cno = $chkey;
		if ( exists $_chrs{$chkey} ) {
			my $cno_file0 = $chinfo{$chkey};
			my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
			$cno =~ s/chr//;
			print $fh_log "phylop wg (100w) for $chkey\n";
			my $phy_name = "phylop:" . $cno;
			$bedops_phylop2_module{$phy_name}{db}       = $phylop_pl_dir;
			$bedops_phylop2_module{$phy_name}{chrkey}   = $chkey;
			$bedops_phylop2_module{$phy_name}{echo_map} = " --echo-map-score";
			$bedops_phylop2_module{$phy_name}{post_process} = "phylop";
		}
	}

	my $this_bedopsphy_module =
	  $ang2->create_bedops_region_chr_pipeline( \%bedops_phylop_module );
	my $this_bedopsphy2_module =
	  $ang2->create_bedops_region_chr_pipeline( \%bedops_phylop2_module );

	$cno = 1;
	my %bedops_dbsnpR_module = ();
	foreach my $chkey ( keys %chinfo ) {
		$cno = $chkey;
		if ( exists $_chrs{$chkey} ) {
			my $cno_file0 = $chinfo{$chkey};
			my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
			$cno =~ s/chr//;
			print $fh_log "dnsnpR  $chkey\n";
			my $dbsnpR_name = "dbsnpR:" . $cno;
			$bedops_dbsnpR_module{$dbsnpR_name}{db}       = $region_dbsnp_bed;
			$bedops_dbsnpR_module{$dbsnpR_name}{chrkey}   = $chkey;
			$bedops_dbsnpR_module{$dbsnpR_name}{echo_map} = " --echo-map-id";
			$bedops_dbsnpR_module{$dbsnpR_name}{post_process} = "dbsnp";
		}
	}

	my $this_dbsnpR_module =
	  $ang2->create_bedops_region_chr_pipeline( \%bedops_dbsnpR_module );

	$cno = 1;
	my %bedops_dbsnpW_module = ();
	foreach my $chkey ( keys %chinfo ) {
		$cno = $chkey;
		if ( exists $_chrs{$chkey} ) {
			my $cno_file0 = $chinfo{$chkey};
			my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
			$cno =~ s/chr//;
			print $fh_log "dnsnpW  $chkey\n";
			my $dbsnpW_name = "dbsnpW:" . $cno;
			$bedops_dbsnpW_module{$dbsnpW_name}{db}        = $region_dbsnp_bed;
			$bedops_dbsnpW_module{$dbsnpW_name}{chrkey}    = $chkey;
			$bedops_dbsnpW_module{$dbsnpW_name}{bed_range} = 7;
			$bedops_dbsnpW_module{$dbsnpW_name}{echo_map}  = " --echo-map-id";
			$bedops_dbsnpW_module{$dbsnpW_name}{post_process} = "dbsnp";
		}
	}


	my %bedops_cgInt_module = ();
	if($run_is_mssng == 1){
		#my %bedops_cgInt_module = ();
		$cno = 1;
		#my %bedops_cgInt_module = ();
		foreach my $chkey ( keys %chinfo ) {
			$cno = $chkey;
			if ( exists $_chrs{$chkey} ) {
				my $cno_file0 = $chinfo{$chkey};
				my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
				$cno =~ s/chr//;
				#print $fh_log "cgInt :  $chkey\n";
				my $cgInt_name = "cgInt:" . $cno;
			$bedops_cgInt_module{$cgInt_name}{db}       = $bed_cgInt;
			$bedops_cgInt_module{$cgInt_name}{chrkey}   = $chkey;
			$bedops_cgInt_module{$cgInt_name}{echo_map} = " --echo-map";
			$bedops_cgInt_module{$cgInt_name}{post_process} = "cgint";
		}
	}
	}

	my %bedops_illInt_module = ();
	if($run_is_mssng == 1){
		#my %bedops_cgInt_module = ();
		$cno = 1;
		#my %bedops_cgInt_module = ();
		foreach my $chkey ( keys %chinfo ) {
			$cno = $chkey;
			if ( exists $_chrs{$chkey} ) {
				my $cno_file0 = $chinfo{$chkey};
				my ( $cno_file, $cnw_file ) = split( "\t", $cno_file0 );
				$cno =~ s/chr//;
				#print $fh_log "cgInt :  $chkey\n";
				my $cgInt_name = "illInt:" . $cno;
			$bedops_illInt_module{$cgInt_name}{db}       = $bed_illInt;
			$bedops_illInt_module{$cgInt_name}{chrkey}   = $chkey;
			$bedops_illInt_module{$cgInt_name}{echo_map} = " --echo-map";
			$bedops_illInt_module{$cgInt_name}{post_process} = "cgint";
		}
	}
	}
	
	#warn Dumper (%bedops_cgInt_module) , "\n";
	my $this_cgInt_module =
	  $ang2->create_bedops_region_chr_pipeline( \%bedops_cgInt_module );

	my $this_illInt_module =
	  $ang2->create_bedops_region_chr_pipeline( \%bedops_illInt_module );


	my $this_dbsnpR_module =
	  $ang2->create_bedops_region_chr_pipeline( \%bedops_dbsnpR_module );
	my $this_dbsnpW_module =
	  $ang2->create_bedops_region_chr_pipeline( \%bedops_dbsnpW_module );

	my $this_dngR_module =
	  $ang2->create_bedops_region_pipeline( \%bedops_region_module );

	my @run_module_names = ();
	my %run_modules      = ();

	my %additional_module = ();

	#warn "**** Gene ***" , $this_gene_module->{'Gene'}->{var_output} , "\n";
	#$db_refFlat

	my $gene_var_out = $this_gene_module->{'Gene'}->{var_output};
	my $gene_vex_out = $this_gene_module->{'Gene'}->{exonic_output};
	my $gene_rlx_out = $this_gene_module->{'Gene-Rlx'}->{exonic_output};
	my $gene_var_apprs_out =
	  ( $run_appris_effect == 1 )
	  ? $this_gene_module->{'Gene-Appris'}->{var_output}
	  : "0";
	my $gene_vex_apprs_out =
	  ( $run_appris_effect == 1 )
	  ? $this_gene_module->{'Gene-Appris'}->{exonic_output}
	  : "0";
	my $gene_sel_out  = $this_gene_module->{'Gene-Select'}->{var_output};
	my $gene_selx_out = $this_gene_module->{'Gene-Select'}->{exonic_output};

#	$additional_module{"gene_extra"}{cmd} =  "perl  $tool_home\/scripts\/geneAnno_wrapper_v2.2.pl $gene_var_out $gene_vex_out $gene_rlx_out $db_refFlat $gene_var_apprs_out $gene_vex_apprs_out";
#	$additional_module{"gene_extra"}{level} =  2;
#	$additional_module{"gene_extra"}{output} =  "gene_ext.tsv";

	#gene_extra chrwise, added Jan 10,2020
	$cno = 1;
	foreach my $chkey ( keys %chinfo ) {
		$cno = $chkey;

		#if(exists $_chrs{$chkey}){
		print $fh_log "gene_extra  $chkey\n";
		my $genext_name = "gene_extra:" . $cno;
		my $this_stats_out =
		    $run_base_dir . "/"
		  . $tmp_directory . "/"
		  . $genext_name
		  . "/gene_ext.stats";
		$additional_module{$genext_name}{cmd} =
"perl  $tool_home\/scripts\/geneAnno_wrapper_v2.9.pl $gene_var_out $gene_vex_out $gene_rlx_out $db_refFlat $gene_var_apprs_out $gene_vex_apprs_out $chkey $gfo_out $morbidmap_file $run_input $this_stats_out $gene_sel_out $gene_selx_out";
		$additional_module{$genext_name}{level}  = 2;
		$additional_module{$genext_name}{output} = "gene_ext.tsv";
		$additional_module{$genext_name}{stats}  = $this_stats_out;

		#}
	}

	my $this_add_module = $ang2->create_custom_pipeline( \%additional_module );

	#push( @all_module, $this_vcf_module );
	push( @all_module, $this_bedopsf_module );
	push( @all_module, $this_bedopsphy_module );
	push( @all_module, $this_bedopsphy2_module );
	push( @all_module, $this_cgInt_module );
	push( @all_module, $this_illInt_module );
	push( @all_module, $this_gene_module );
	push( @all_module, $this_filter_module );
	push( @all_module, $this_region_module );
	push( @all_module, $this_dbsnpR_module );
	push( @all_module, $this_dbsnpW_module );
	push( @all_module, $this_dngR_module );
	push( @all_module, $this_bedopcl_module );
	push( @all_module, $this_add_module );

	foreach my $md (@all_module) {
		my @this_mods = keys %{$md};
		push( @job_names, @this_mods );
		foreach (@this_mods) {
			$process_status{$_}{command}    = $md->{$_}{command};
			$process_status{$_}{load_type}  = $md->{$_}{load_type};
			$process_status{$_}{error_file} = $md->{$_}{error_file};

			if ( exists $md->{$_}{output} ) {
				$process_status{$_}{output} = $md->{$_}{output};
			}
			if ( exists $md->{$_}{var_output} ) {
				$process_status{$_}{var_output} = $md->{$_}{var_output};
			}
			if ( exists $md->{$_}{exonic_output} ) {
				$process_status{$_}{exonic_output} = $md->{$_}{exonic_output};
			}
			if ( exists $md->{$_}{database} ) {
				$process_status{$_}{database} = $md->{$_}{database};
			}
			if ( exists $md->{$_}{level} ) {
				$process_status{$_}{level} = $md->{$_}{level};
			}
			if ( exists $md->{$_}{stats} ) {
				$process_status{$_}{stats} = $md->{$_}{stats};
			}

		}
	}

##    my @bedops1_modules = keys %{$this_bedopsf_module};
##    push(@job_names , @bedops1_modules);
	#   	my @bedops2_modules = keys %{$this_bedopsphy_module};
	#    push(@job_names , @bedops2_modules);
	#
	# 	my @bedops3_modules = keys %{$this_bedopsphy2_module};
	#    push(@job_names , @bedops3_modules);
	#
	#	my @filer_modules = keys %{$this_filter_module};
	#    push(@job_names , @filer_modules);
	#
	#	my @gene_modules = keys %{$this_gene_module};
	#    push(@job_names , @gene_modules);
	#
	#
	#	my @region_modules = keys %{$this_region_module};
	#    push(@job_names , @region_modules);
	#
	# 	my @bedops_dbR_modules = keys %{$this_dbsnpR_module};
	#    push(@job_names , @bedops_dbR_modules);
	# 	my @bedops_dbW_modules = keys %{$this_dbsnpW_module};
	#    push(@job_names , @bedops_dbW_modules);
	#
	#
	#    foreach (@bedops1_modules){
	#    	$process_status{$_}{command} = $this_bedopsf_module->{$_}{command};
	#    }
	#    foreach (@bedops2_modules){
	#    	$process_status{$_}{command} = $this_bedopsphy_module->{$_}{command};
	#    }
	#    foreach (@bedops3_modules){
	#    	$process_status{$_}{command} = $this_bedopsphy2_module->{$_}{command};
	#    }
	#    foreach (@filer_modules){
	#    	$process_status{$_}{command} = $this_filter_module->{$_}{command};
	#    }
	#    foreach (@gene_modules){
	#    	$process_status{$_}{command} = $this_gene_module->{$_}{command};
	#    }
	#    foreach (@region_modules){
	#    	$process_status{$_}{command} = $this_region_module->{$_}{command};
	#    }
	#    foreach (@bedops_dbR_modules){
	#    	$process_status{$_}{command} = $this_dbsnpR_module->{$_}{command};
	#    }
	#    foreach (@bedops_dbW_modules){
	#    	$process_status{$_}{command} = $this_dbsnpW_module->{$_}{command};
	#    }

	print STDOUT "** input2go= ", $process_status{'pipeline'}{input_to_go},
	  "\n";
	print STDOUT "\n ** Initiating Fork manager..\n";

	print $fh_log Dumper %process_status, "\n";

	my $ang0 =
	  AnnotationEngine->new( \%process_status, \@job_names, $monitor_out );
	my @run_st1 = $ang0->fork_manager2($cores);

	#push(@run_st1 , $this_vcf_module);
	print "*** Fork manager returns with ", scalar(@run_st1),
	  " unfinished jobs\n";
	if ( scalar(@run_st1) > 0 ) {
		print STDOUT "Restarting following jobs:\n";
		print STDOUT join( " , ", @run_st1 ), "\n";
		$ang0->fork_manager($cores);
	}

	#meta file
	foreach my $kp ( sort keys %process_status ) {
		print $fh_mta "[", $kp, "]\n";
		foreach my $kps ( keys %{ $process_status{$kp} } ) {
			print $fh_mta $kp, "->", $kps, "=", $process_status{$kp}{$kps},
			  "\n";
		}
	}
	close $fh_mta;

	#compile output
	#final merge
	print $fh_log "Final merge: \n";
	my $mrg_out_file =
	    $run_base_dir . "/"
	  . $input_basename
	  . ".annovar.out_"
	  . $pipeline_rev . ".tsv";
	if ( $run_keep_full == 1 ) {
		$mrg_out_file =
		    $log_dir . "/"
		  . $input_basename
		  . ".annovar.out_"
		  . $pipeline_rev . ".tsv";
	}
	my $mrg_e       = $log_dir . "/" . $input_basename . ".final.merge.log";
	my $mrg_tmp_dir = $run_base_dir . "/" . $tmp_directory;
	my $mrg_command =
"perl $tool_home\/scripts\/compile_results.pl -m $meta_file -t $mrg_tmp_dir > $mrg_out_file  2> $mrg_e";
	print $fh_log "$mrg_command\n";
	my $mrg_start_time = localtime;
	$process_status{Final_merge}{start_time} = $mrg_start_time;
	my $ex_st        = system($mrg_command);
	my $mrg_fin_time = localtime;
	$process_status{Final_merge}{end_time}    = $mrg_fin_time;
	$process_status{Final_merge}{exit_status} = $ex_st;
	$process_status{Final_merge}{output}      = $mrg_out_file;
	$process_status{Final_merge}{command}     = $mrg_command;
	$process_status{Final_merge}{db}          = "NA";
	$process_status{Final_merge}{db_version}  = "NA";
	$process_status{'pipeline'}{output}       = $mrg_out_file;

	if ( $ex_st == 0 ) {
		print $fh_proc "*** Final_merge is finished  with exit code: $?\n";
		print STDOUT "Final_merge is finished  with exit code: $?\n";
	}
	else {
		print $fh_proc "Final_merge is failed with exit code: $?\n";
		warn "Final_merge is failed with exit code: $?\n";
		open( ERROUT, ">$mrg_out_file" );
		close ERROUT;
		usage("Critical: Final merge is failed\n(Details: $mrg_e) \n");
	}

	#stats

	#merging dng annotation if exists
	my $dng_merge_out = $mrg_out_file;

# 	if($run_dng_file == 1){
#		warn "Merging DNG annotations:\n";
#		$dng_merge_out = $run_base_dir . "/" . basename($mrg_out_file) . "_DNG_merged.tsv";
#		my $merge_dng_ext = merge_dng($mrg_out_file , $dng_merge_out , \%process_status );
#		if($merge_dng_ext != 0){
#			usage("Error with DNG merge!\n");
#		}
#	}

	#check exome target file for exome annotations
	my $exome_target_dist_bed = "NA";

#(exists  $process_status{'target-dist'}{output}) ? $process_status{'target-dist'}{output} :
	if ( exists $process_status{'target-dist'}{output} ) {
		$exome_target_dist_bed = $process_status{'target-dist'}{output};
		if ( $process_status{'target-dist'}{exit_status} != 0 ) {
			die "Cirical! Module error: target-dist failed..\n";
		}
	}

	my $to_validFinal = $dng_merge_out;

	#post processing
	if ( not( $run_type_ppr == 0 || $run_type_ppr == 5 ) ) {

		my %dng_samples = ();
		if ( $run_arg->{'dng_meta'} ne "NA" ) {
			open( DMT, $run_arg->{'dng_meta'} )
			  or die "$! cannot open dng meta file $run_arg->{'dng_meta'}\n";
			while ( my $dng_line = <DMT> ) {
				chomp($dng_line);
				my ( $dng_s, $dng_f ) = split( "\t", $dng_line );
				$dng_samples{$dng_s} = $dng_f;
			}
			close DMT;
		}

		my $formatted_mrg_out_file =
		    $log_dir . "/"
		  . $input_basename
		  . ".annovar.out_FINAL_"
		  . $pipeline_rev . ".tsv";
		if ( $no_bgzip == 0 ) {
			$formatted_mrg_out_file =
			    $log_dir . "/"
			  . $input_basename
			  . ".annovar.out_FINAL_"
			  . $pipeline_rev
			  . ".tsv.gz";
		}
		my $formatted_filtered_out_file =
		    $log_dir . "/"
		  . $input_basename
		  . ".annovar.out_SUBSET_"
		  . $pipeline_rev . ".tsv";
		my $pp_ret = -1;
		if ( $run_type_ppr == 5 ) {

#$pp_ret = Parse::Annovar::format_annotationMSSNG($dng_merge_out , $vcf_smp_file , $run_type_ppr , $formatted_mrg_out_file , $formatted_filtered_out_file, $add_cols, $exome_target_dist_bed);
		}
		else {
			$pp_ret = Parse::Annovar::format_annotation(
				$dng_merge_out,               $vcf_smp_file,
				$run_type_ppr,                $formatted_mrg_out_file,
				$formatted_filtered_out_file, $add_cols,
				$exome_target_dist_bed,       $no_bgzip,
				\%dng_samples
			);
			warn
"Running post-processing.. Parse::Annovar::format_annotation\($dng_merge_out , $vcf_smp_file , $run_type_ppr , $formatted_mrg_out_file , $formatted_filtered_out_file , $add_cols , $exome_target_dist_bed, $no_bgzip, \%dng_samples\)\n";
		}
		if ( $pp_ret != 0 ) {
			usage("Error making final file : $formatted_mrg_out_file..!\n");
		}
		print STDOUT "Post-processing finshed with exit status $pp_ret\n";
		print $fh_proc "Post-processing finshed with exit status $pp_ret\n";
		$process_status{'pipeline'}{final_output}  = $formatted_mrg_out_file;
		$process_status{'pipeline'}{exit_status}   = $pp_ret;
		$process_status{Final_format}{exit_status} = $pp_ret;
		$process_status{Final_format}{output}      = $formatted_mrg_out_file;
		$process_status{Final_format}{command} =
"pm: Parse::Annovar::format_annotation\($dng_merge_out , $vcf_smp_file , $run_type_ppr , $formatted_mrg_out_file , $formatted_filtered_out_file, $add_cols, $exome_target_dist_bed , $no_bgzip, \%dng_samples\)";
		$process_status{Final_format}{db}         = "NA";
		$process_status{Final_format}{db_version} = "NA";
		push( @job_names, "Final_format" );
		unlink $mrg_out_file unless ( $run_keep_full == 1 );   #added Sep07,2018
		$to_validFinal = $formatted_mrg_out_file;

		if ( $no_bgzip == 0 ) {
			print STDOUT "tabix FINAL output\n";
			my $tabix_cmd = "tabix -f -s 1 -b 2 -e 3 $formatted_mrg_out_file";
			print STDOUT "$tabix_cmd\n";
			my $ex_tabix = system($tabix_cmd);

			if ( $ex_tabix == 0 ) {
				print STDOUT "tabix finished..\n";
			}
			else {
				usage("Error!: tabix command failed ( $tabix_cmd ) ");
			}
		}

	}

	if ( not( $run_type_ppr == 0 || $run_type_ppr == 5 ) ) {
		$no_bgzip = 1;
	}

	#tabix if bgzipped
	#tabix -s 1 -b 2 -e 3 89931_100_Full_Rare05_Dmg.txt.gz

	#column validation
	my $valid_out =
	  $run_base_dir . "/" . $tmp_directory . "/" . $input_basename . "_.err";
	warn
"Running validation on output(using first 2M variants).. Parse::Annovar::run_validation\($to_validFinal , $valid_out\)\n";
	Parse::Annovar::run_validation( $to_validFinal, $valid_out, $no_bgzip );

	#make summary file
	#test_small.txt_ext.tsv.stats.meta
	#pipeline->run_type=t
	#$vcfp_sum

	my $cmp_summary = $run_base_dir . "/" . $tmp_directory . "/stats.meta";
	my $fh_cmpsum = IO::File->new( $cmp_summary, q{<} )
	  or usage("$! $cmp_summary");

	if ( $run_type_original eq "u" || $run_type_original eq "mg" ) {
		my $vcfp_sum = $process_status{'vcf_pp'}{stat_file};
		my $fh_vcfpsum = IO::File->new( $vcfp_sum, q{<} )
		  or usage("$! $vcfp_sum");

		while ( my $line = <$fh_vcfpsum> ) {
			chomp($line);
			print SUM $line, "\n";
		}
		close $fh_vcfpsum;
	}

	print SUM "\n>>Output summary: \n";
	while ( my $line = <$fh_cmpsum> ) {
		chomp($line);
		print SUM $line, "\n";
	}
	close $fh_cmpsum;

	#$annovar_in
	#test_small.txt_ext.tsv.warnings.txt
	my $warn_file = $run_base_dir . "/" . $tmp_directory . "/warnings.txt";
	my $fh_warn = IO::File->new( $warn_file, q{<} ) or usage("$! $warn_file");
	print SUM "\n>>Following errors/warnings are ingnored by Pipeline: \n";
	while ( my $line = <$fh_warn> ) {
		chomp($line);
		print SUM $line, "\n";
	}
	close $fh_warn;

	my $fh_valid = IO::File->new( $valid_out, q{<} ) or usage("$! $valid_out");
	print SUM "\n>>Output validation results ( using first 2M variants): \n";
	while ( my $line = <$fh_valid> ) {
		chomp($line);
		print SUM $line, "\n";
	}
	close $fh_valid;

	my $monitor_out_post =
	  $log_dir . "/" . $input_basename . "_Annotation_workflow.json";
	my $ang_post =
	  AnnotationEngine->new( \%process_status, \@job_names, $monitor_out_post );
	$ang_post->draw_workflow_json3();

}    #run_annotation

sub check_1000g_db {
	my ($dbname) = @_;
	my $db_file = $dbname;
	if ( $dbname =~ m/^1000g(\d\d\d\d)([a-z]{3})_([a-z]+)$/ ) {
		my %monthhash = (
			'jan' => '01',
			'feb' => '02',
			'mar' => '03',
			'apr' => '04',
			'may' => '05',
			'jun' => '06',
			'jul' => '07',
			'aug' => '08',
			'sep' => '09',
			'oct' => '10',
			'nov' => '11',
			'dec' => '12'
		);
		$db_file = uc($3) . '.sites.' . $1 . '_' . $monthhash{$2};
	}
	return $db_file;
}

sub print_versions {
	my $param       = shift;
	my $dbv_logfile = shift;
	my %vers        = %$param;
	my $fh_dbvr     = IO::File->new( $dbv_logfile, q{>} )
	  or die "$! $dbv_logfile\n";
	print $fh_dbvr JSON->new->pretty->encode( \%vers ), "\n";
	close $fh_dbvr;
}

sub html_report {
	my ( $stat_file, $html_file ) = @_;

}

sub merge_dng {
	my ( $an_out, $an_dng_out, $pr_meta ) = @_;

	my $dng_fil_db =
	  ( exists $pr_meta->{'filter_DNG'}{database} )
	  ? $pr_meta->{'filter_DNG'}{database}
	  : usage("DNG filter database missing!");

	open( ANN, $an_out ) or die "$an_out $!";

	#filter_DNG->output
	my $dng_fil =
	  ( exists $pr_meta->{'filter_DNG'}{output} )
	  ? $pr_meta->{'filter_DNG'}{output}
	  : -1;
	warn "*** DNG filter = $dng_fil\n";
	open( DNF, $dng_fil ) or die "$dng_fil $!";

#    my $dng_reg = (exists  $pr_meta->{'region_DNG'}{output} ) ?  $pr_meta->{'region_DNG'}{output} : -1;
#    warn "*** DNG region = $dng_reg\n";
#	open(DNR, $dng_reg) or die "$dng_reg $!";

	open( DNO, ">$an_dng_out" ) or die "$an_dng_out $!";

	open( DB, $dng_fil_db ) or die " $dng_fil_db $!";
	my $header_db = <DB>;
	close DB;
	chomp($header_db);

	my %dnf = ();

	#my %dnr = ();

#my $filter_fields = "MQ_DAD:MQ_MOM:MQ_NORMAL:PairSNPcode:RD_DAD:RD_MOM:RD_NORMAL:SNPcode:code:DNM_CONFIG:ML_DNM:ML_NULL:MQ:MQ_T:NULL_CONFIG:PP_DNM:PP_NULL:RD"; #=48:48:.:.:27:15:.:2:9:GG/CC/CG:4.776e-12:3.00631e-08:48:.:CG/CC/CG:0.000146567:0.999853:13
#INDELcode,MQ_DAD,MQ_MOM,MQ_NORMAL,PairSNPcode,RD_DAD,RD_MOM,RD_NORMAL,SNPcode,code,3_0781_000:MQ,3_0781_000:MQ_T,3_0781_000:PP_DNM,3_0781_000:RD,3_0781_000:RD_T,3_0781_000:NULL_CONFIG,3_0781_000:DNM_CONFIG,3_0781_000:PP_NULL,3_0781_000:ML_NULL,3_0781_000:ML_DNM,3_0781_000:Zygosity
	my $filter_fields = ( split( "\t", $header_db ) )[5];
	while ( my $line = <DNF> ) {
		chomp($line);
		my @fields = split( "\t", $line );
		my $key =
		    $fields[2] . ":"
		  . $fields[3] . ":"
		  . $fields[4] . ":"
		  . $fields[5] . ":"
		  . $fields[6];
		my $val = $fields[1];
		my $i   = 0;
		foreach my $fv ( split( ",", $filter_fields ) ) {
			my $fv2go = $fv;
			if ( $fv =~ /:/ ) {
				$fv2go = ( split( ":", $fv ) )[1];
			}
			$dnf{$key}{$fv2go} = ( split( ",", $val ) )[ $i++ ];

			#print "$key -- $fv2go ==> " , $dnf{$key}{$fv2go} , "\n";
		}
		$dnf{$key}{'dng_key'} = $key;
	}
	close DNF;

	warn "Loaded filter annotations\n";

#1     2690677 2690678 MQ_DAD:MQ_MOM:MQ_NORMAL:PairSNPcode:RD_DAD:RD_MOM:RD_NORMAL:SNPcode:code:DNM_CONFIG:ML_DNM:ML_NULL:MQ:MQ_T:NULL_CONFIG:PP_DNM:PP_NULL:RD=21:21:.:.:66:33:.:2:9:AC/CC/CC:9.9301e-09:1.89686e-06:21:.:AC/CC/AC:0.00516514:0.994835:54     1:2690678:2690678:C:A
#info = chr1     822865  822866  .,.,.,38,38,.,.,.,.,232,254,.,2,9,.,38,.,0.000829009,243,.,unknown;chr1 822865  822866  .,.,.,38,38,.,.,.,.,232,254,.,2,9,.,38,.,0.000829009
#	while(my $line = <DNR>){
#		chomp($line);
#		my ($input, $info) = split('\|' , $line);
#		my @infos = split(";", $info);
#		foreach my $this_info (@infos){
#			my $info3 = (split("\t" , $this_info))[3];
#			my $val = $info3;
#			my $dng_key = (split("\t" , $this_info))[4]; ;
#		#	print "$dng_key\n";
#			my @fields = split("\t" , $input);
#			#my $key = join(":" , @fields);
#			my $key = $fields[0] . ":" . ($fields[1] + 1) . ":" . $fields[2] . ":" . $fields[3] . ":" . $fields[4];
#			warn "***DNG key = $key\n";
#			$dnr{$key}{'dng_key'} = (exists $dnr{$key}{'dng_key'}) ?  $dnr{$key}{'dng_key'} . "," . $dng_key : $dng_key;
#			#print "DNG key for $key =" , $dnr{$key}{'dng_key'} , "\n";
#			my $i = 0;
#			foreach my $fv (split("," , $filter_fields)){
#				my $fv2go = $fv;
#				if($fv =~ /\:/){
#					$fv2go = (split(":" , $fv))[1];
#				}
#				$dnr{$key}{$fv2go} =   (exists $dnr{$key}{$fv2go}) ? ($dnr{$key}{$fv2go} . "," . (split("," , $val))[$i++]) :   (split("," , $val))[$i++];
#	#			print "$key ,  $dng_key -- $fv2go ==> " , $dnr{$key}{$fv} , "\n";
#			}
#		}
#	}
#	close DNR;
#
#	warn "Loaded region annotations\n";

	my $header = <ANN>;
	chomp($header);

	my %ann_hd_idx = ();
	my $idx        = 0;
	foreach ( split( "\t", $header ) ) {
		$ann_hd_idx{$_} = $idx++;
	}

	my $idx_annovar_chr =
	  ( exists $ann_hd_idx{'annovar_chr'} )
	  ? $ann_hd_idx{'annovar_chr'}
	  : die "annovar_chr idx error\n";
	my $idx_annovar_start =
	  ( exists $ann_hd_idx{'annovar_start'} )
	  ? $ann_hd_idx{'annovar_start'}
	  : die "annovar_start idx error\n";
	my $idx_annovar_end =
	  ( exists $ann_hd_idx{'annovar_end'} )
	  ? $ann_hd_idx{'annovar_end'}
	  : die "annovar_end idx error\n";
	my $idx_annovar_ref =
	  ( exists $ann_hd_idx{'ref_allele'} )
	  ? $ann_hd_idx{'ref_allele'}
	  : die "ref_allele idx error\n";
	my $idx_annovar_alt =
	  ( exists $ann_hd_idx{'alt_allele'} )
	  ? $ann_hd_idx{'alt_allele'}
	  : die "alt_allele idx error\n";

	warn "annovar key indexes : \{$idx_annovar_chr .. $idx_annovar_alt\}\n";

	print DNO
"$header\tDNG_exact:key\tDNG_exact:RD_DAD\tDNG_exact:RD_MOM\tDNG_exact:RD_PROBAND\tDNG_exact:PP_DNM\tDNG_exact:NULL_CONFIG\tDNG_exact:DNM_CONFIG\n";

#my $filter_fields = "MQ_DAD:MQ_MOM:MQ_NORMAL:PairSNPcode:RD_DAD:RD_MOM:RD_NORMAL:SNPcode:code:DNM_CONFIG:ML_DNM:ML_NULL:MQ:MQ_T:NULL_CONFIG:PP_DNM:PP_NULL:RD"; #=48:48:.:.:27:15:.:2:9:GG/CC/CG:4.776e-12:3.00631e-08:48:.:CG/CC/CG:0.000146567:0.999853:13
	while ( my $line = <ANN> ) {
		chomp($line);
		my @fields = split( "\t", $line );
		my $key =
		    $fields[$idx_annovar_chr] . ":"
		  . $fields[$idx_annovar_start] . ":"
		  . $fields[$idx_annovar_end] . ":"
		  . $fields[$idx_annovar_ref] . ":"
		  . $fields[$idx_annovar_alt];

		#print "keys = $key\n";
		my $filter_rd_dad =
		  ( exists $dnf{$key}{'RD_DAD'} ) ? $dnf{$key}{'RD_DAD'} : "NA";
		my $filter_rd_mom =
		  ( exists $dnf{$key}{'RD_MOM'} ) ? $dnf{$key}{'RD_MOM'} : "NA";
		my $filter_rd_child =
		  ( exists $dnf{$key}{'RD'} ) ? $dnf{$key}{'RD'} : "NA";
		my $filter_pp_dnm =
		  ( exists $dnf{$key}{'PP_DNM'} ) ? $dnf{$key}{'PP_DNM'} : "NA";
		my $filter_dnm_config =
		  ( exists $dnf{$key}{'DNM_CONFIG'} ) ? $dnf{$key}{'DNM_CONFIG'} : "NA";
		my $filter_null_config =
		  ( exists $dnf{$key}{'NULL_CONFIG'} )
		  ? $dnf{$key}{'NULL_CONFIG'}
		  : "NA";
		my $filter_ml_dnm =
		  ( exists $dnf{$key}{'ML_DNM'} ) ? $dnf{$key}{'ML_DNM'} : "NA";
		my $filter_dng_key =
		  ( exists $dnf{$key}{'dng_key'} ) ? $dnf{$key}{'dng_key'} : "NA";

#		my $region_rd_dad = (exists $dnr{$key}{'RD_DAD'}) ? $dnr{$key}{'RD_DAD'} : "NA";
#		my $region_rd_mom = (exists $dnr{$key}{'RD_MOM'}) ? $dnr{$key}{'RD_MOM'} : "NA";
#		my $region_rd_child = (exists $dnr{$key}{'RD'}) ? $dnr{$key}{'RD'} : "NA";
#		my $region_pp_dnm = (exists $dnr{$key}{'PP_DNM'}) ? $dnr{$key}{'PP_DNM'} : "NA";
#		my $region_dnm_config = (exists $dnr{$key}{'DNM_CONFIG'}) ? $dnr{$key}{'DNM_CONFIG'} : "NA";
#		my $region_null_config = (exists $dnr{$key}{'NULL_CONFIG'}) ? $dnr{$key}{'NULL_CONFIG'} : "NA";
#		my $region_ml_dnm = (exists $dnr{$key}{'ML_DNM'}) ? $dnr{$key}{'ML_DNM'} : "NA";
#		my $region_dng_key = (exists $dnr{$key}{'dng_key'}) ? $dnr{$key}{'dng_key'} : "NA";
		my $dng_conf = "NA";

		#    	if( $filter_pp_dnm ne "NA"){
##			$dng_conf = ($region_pp_dnm > 0.9 || $filter_pp_dnm > 0.9) ? "High" : "Low";
		#			$dng_conf = get_cfd($filter_pp_dnm);
		#    	}

		print DNO $line, "\t", $filter_dng_key, "\t", $filter_rd_dad, "\t",
		  $filter_rd_mom, "\t", $filter_rd_child, "\t", $filter_pp_dnm, "\t",
		  $filter_null_config, "\t", $filter_dnm_config, "\n";
	}
	close DNO;
	close ANN;
	close DNF;

	#	close DNR;

	return 0;

}

sub get_cfd {
	my ($flt) = @_;
	my $ret_cfd = "Low";
	if ( $flt >= 0.9 ) {
		$ret_cfd = "High";
	}

	#	foreach my $v (split(",", $rgn)){
	#		if($v >= 0.9){
	#			$ret_cfd = "High";
	#		}
	#	}
	return $ret_cfd;
}

#added for dng1.1
sub get_cfd_ext {
	my ($flt) = @_;
	my $ret_cfd = "Low";
	if ( $flt >= 0.9 ) {
		$ret_cfd = "High";
	}

	#	foreach my $v (split(",", $rgn)){
	#		if($v >= 0.9){
	#			$ret_cfd = "High";
	#		}
	#	}
	return $ret_cfd;
}

sub check_tool {
	my $tool_exe = shift;
	my $tool_ret = system($tool_exe);
	return $tool_ret;
}

sub check_loaded_modules {
	my $loaded = $ENV{LOADEDMODULES};
	warn "LOADEDMODULES = $loaded\n";
	warn "PATH= ", $ENV{PATH}, "\n";
	if ( $loaded =~ /tabix/ ) {
		print STDOUT "tabix OK..\n";
	}
	else {

		warn "\n**** WARNING! tabix is missing in loaded modules..**** \n\n";
	}
}

#MSSNG00131      MSSNG00131_002  0       0       1       0
#MSSNG00131      MSSNG00131_001  0       0       2       0
#MSSNG00131      MSSNG00131_003  MSSNG00131_002  MSSNG00131_001  2       0
#	  Family ID
#     Individual ID
#     Paternal ID
#     Maternal ID
#     Sex (1=male; 2=female; other=unknown)
#     Phenotype

sub process_PED {
	my ($pd_file) = @_;
	my %ped = ();
	my $fh_pd      = IO::File->new( $pd_file, q{<} ) or die "$! $pd_file\n";
	my $this_child = -1;
	my $this_mom   = -1;
	my $this_dad   = -1;

}

##FORMAT=<ID=NULL_CONFIG,Number=1,Type=String,Description="NULL trio configuration (child/mom/dad)">
##FORMAT=<ID=ML_NULL,Number=1,Type=Float,Description="Maximum Likelihood for the NULL configuration">
##FORMAT=<ID=PP_NULL,Number=1,Type=Float,Description="Posterior probability for the NULL configuration">
##FORMAT=<ID=DNM_CONFIG,Number=1,Type=String,Description="DNM trio configuration (child/mom/dad)">
##FORMAT=<ID=ML_DNM,Number=1,Type=Float,Description="Maximum Likelihood for the DNM configuration">
##FORMAT=<ID=PP_DNM,Number=1,Type=Float,Description="Posterior probability for the DNM configuration">
##FORMAT=<ID=MQ,Number=1,Type=Integer,Description="Mapping quality of the child">
##FORMAT=<ID=RD,Number=1,Type=Integer,Description="Read Depth of the child">
##FORMAT=<ID=pair_null_code,Number=1,Type=Float,Description="">
##FORMAT=<ID=pair_denovo_code,Number=1,Type=Float,Description="">

#1       #CHROM
#2       POS
#3       ID
#4       REF
#5       ALT
#6       QUAL
#7       FILTER

#sub make_final_summary{
#
#	my ($s_in, $s_out, $w_file, $fs_out) = @_;
#	#open(STIN, $s_in) or die "$!";
#	my $fh_stin = IO::File->new($s_in , q{<}) or die "$! $s_in\n";
#	#open(STOU, $s_out) or die "$!";
#	my $fh_stou = IO::File->new($s_out , q{<}) or die "$! $s_out\n";
#
#	#open(VCFW, $w_file) ;
#	my $fh_vcfw = IO::File->new($w_file , q{<}) or die "$! $w_file\n";
#
#    #open(FSO, ">$fs_out") or die "error $fs_out\n" ;
#	my $fh_fso = IO::File->new($fs_out , q{>}) or die "$! $fs_out\n";
#
#	my %stin = ();
#	my %stou = ();
#
#	while(my $line = <$fh_stin>){
#		chomp($line);
#		my ($key, $val) = split("=", $line);
#		$key =~ s/^\s+//; #remove leading spaces
#		$key =~ s/\s+$//; #remove trailing spaces
#		$val =~ s/^\s+//; #remove leading spaces
#		$val =~ s/\s+$//; #remove trailing spaces
#		$stin{$key} = $val;
#	}
#
#	while(my $line = <$fh_stou>){
#		chomp($line);
#		my ($key, $val) = split(":", $line);
#		$key =~ s/^\s+//; #remove leading spaces
#		$key =~ s/\s+$//; #remove trailing spaces
#		$val =~ s/^\s+//; #remove leading spaces
#		$val =~ s/\s+$//; #remove trailing spaces
#		#print "$key---$val\n";our $DATE =     '$Date: 2019-10-24 00:05:27 -0400 (Thu, 24 Oct 2019) $';
our $AUTHOR =   '$Author: kaichop <kaichop@gmail.com> $';
#		$stou{$key} = $val;
#	}
#
#	my $actual_tot_out = $stin{Total} - ( $stin{UNKNOWN} - $stin{multi_allele});
#
#	print $fh_fso "INPUT STATS:\n";
#	print $fh_fso "------------\n";
#	foreach my $k (sort (keys %stin) ){
#		print $fh_fso $k, " = " , $stin{$k} , "\n"  unless ($k eq "");
#		$process_status{'pipeline'}{$k} = $stin{$k};
#	}
#
#	print $fh_fso "\nOUTPUT STATS:\n";
#	print $fh_fso "------------\n";
#	foreach my $k (sort (keys %stou) ) {
#		print $fh_fso $k, " = " , $stou{$k} , "\n"  unless ($k eq "");
#		$process_status{'pipeline'}{$k} = $stou{$k};
#	}
#
#
#	print $fh_fso  "\nExonic = " , $stou{Exonic} , "\n";
#	print $fh_fso  ">>refseq_Unknown_effect = " , $stou{refseq_Unknown_effect} , "\n";
#	print $fh_fso  ">>Unknown_effect(refseq + UCSC) = " , $stou{UNKNOWN} , "\n";
#	print $fh_fso  ">>nonsynonymous SNV = " , $stou{'nonsynonymous SNV'} , "\n";
#	print $fh_fso  ">>synonymous SNV = " , $stou{'synonymous SNV'} , "\n";
#	print $fh_fso  ">>stopgain = " , $stou{'stopgain'} , "\n";
#	print $fh_fso  ">>stoploss = " , $stou{'stoploss'} , "\n";
#	print $fh_fso "inputs : Input_total - (Unknowns - multialleles) =  " , $actual_tot_out , "\n";
#	my $out_total = $stou{Total};
#	print $fh_fso "Diff = ", ($actual_tot_out-$out_total) , "\n";
#	$process_status{'pipeline'}{'Diff'} = ($actual_tot_out-$out_total);
#	print $fh_fso "\nErrors/Warnings ignored by pipeline:\n";
#	print $fh_fso "-------------------------\n";
#	while(my $line = <$fh_vcfw>){
#		print $fh_fso "$line";
#	}
#	close $fh_vcfw;
#	close $fh_fso;
#}

=head1 SYNOPSIS

 	run_snvAnnotation.pl -i|input <input-file> -f|config <config-file> -m|type <run-type> -o|outdir <work-dir> -r|threads <number of core> 
 	
		
	<input-file> can be vcf,mastervar or plain text format(1-based coordinates)
	<run-type>  can be 'm' for mastervar , 'u' for vcf with normalization and 't' for text-format(annovar-format).
			
		
	Optional arguments:
	  --post-type|c <int>		Post-processing type ; 1=GATK wgs , 2=HAS wgs, 3.7=GATK exome , 0=None (Default 0)
	  --genome|g <string>		Reference genome file. This is required for vcf normalization. Use the same genome file used for variant calls.
	  --logdir|l <string>		Directory for log files. This is useful if you are using /tmp or localdisk as work-dir (-o) for which you can monitor the progress 
	  				of the pipeline via contents in this directory.
	  --cov-file|v	<string>	Coverage file(dp) file exome annotation.
	  --dng-file|b	<string>	vcf-file(s) from Denovogear. For multiple probands, provide DNG files as comma-separated.
	  --exome-target|t <string>	Target bed file for exome annotation.
	  --keep_temp|k			Keep raw annotation output. 
	  --somatic|s			If the input is from somatic variant calling (beta)
	  --pgx|x			Process PGx vcf file; Use this option if the input vcf file includes ref calls
	  --out_config			file contain output columns to be displayed, text file with one column per row.
	  --no_hgmd 			skip HGMD annotations (otherwise perform annotation with professional HGMD database)
	  --splicing_threshold		distance between splicing variants and exon/intron boundary (default: 15)
	  --neargene			distance threshold to define upstream/downstream of a gene ( default 1000) 		
	  --no_bgzip|q			flag to avoid bgzipping and indexing FINAL annotation 
	  --check-ref			Similar to bcftools norm --check-ref, only 'w', 'e' or 's' allowed (default 'e')
	  --hgvs			use HGVS format for exonic annotation (c.122C>T rather than c.C122T) (annovar gene-based annotation)
	  --exonicsplicing		report exonic variants near exon/intron boundary as 'exonic;splicing' variants
	  --help|h			This help info
	  
	  Required perl5 and special perl modules. Pipeline many annovar and custom databases. Contact us for more details. 
	  					
=cut

